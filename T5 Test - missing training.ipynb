{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a0e6a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train', 'validation', 'test'])\n",
      "Size of train dataset:  (157252, 3)\n",
      "Size of Validation dataset:  (5599, 3)\n",
      "dict_keys(['headline', 'text', 'title'])\n",
      " Example of text:  If you're a photographer, keep all the necessary lens, cords, and batteries in the same quadrant of your home or studio. Paints should be kept with brushes, cleaner, and canvas, print supplies should be by the ink, etc. Make broader groups and areas for your supplies to make finding them easier, limiting your search to a much smaller area. Some ideas include:\n",
      "\n",
      "\n",
      "Essential supplies area -- the things you use every day.\n",
      "Inspiration and reference area.\n",
      "Dedicated work area .\n",
      "Infrequent or secondary supplies area, tucked out of the way.;\n",
      ", This doesn't mean cleaning the entire studio, it just means keeping the area immediately around the desk, easel, pottery wheel, etc. clean each night. Discard trash or unnecessary materials and wipe down dirty surfaces. Endeavor to leave the workspace in a way that you can sit down the next day and start working immediately, without having to do any work or tidying.\n",
      "\n",
      "\n",
      "Even if the rest of your studio is a bit disorganized, an organized workspace will help you get down to business every time you want to make art.\n",
      " As visual people, a lot of artist clutter comes from a desire to keep track of supplies visually instead of tucked out of sight. By using jars, old glasses, vases, and cheap, clear plastic drawers, you can keep things in sight without leaving it strewn about haphazardly. Some ideas, beyond those just mentioned, include:\n",
      "\n",
      "\n",
      "Canvas shoe racks on the back of the door\n",
      "Wine racks with cups in each slot to hold pens/pencils.\n",
      "Plastic restaurant squirt bottles for paint, pigment, etc., Simply string up the wires across a wall or along the ceiling and use them to hold essential papers that you don't want to cut or ruin with tacks or tape. Cheap and easy, this is also a good way to handle papers and ideas you touch regularly or need to pin up and down for inspiration., Shelving is an artist's best friend and is a cheap and easy way to get more room in your studio or art space. Don't be afraid to get up high either, especially for infrequently used supplies. The upper reaches of the room are often the most under-utilized, but provide vital space for all your tools and materials., Turning one wall into a chalkboard gives you a perfect space for ideas, sketches, and planning without requiring extra equipment or space. You can even use it for smaller areas. Paint over jars or storage equipment, allowing you to relabel them with chalk as your needs change.\n",
      " A lot of disorganization comes when you keep moving the location of things, trying to optimize your space by reorganizing frequently. This usually has the opposite effect, leading to lost items and uncertainty when cleaning, but an afternoon with a label maker can solve everything. Instead of spending all of your mental energy looking for or storing things, you can just follow the labels, freeing your mind to think about art., Once a month, do a purge of your studio. If it isn't essential or part of a project, either throw it out or file it away for later. Artists are constantly making new things, experimenting, and making a mess. This is a good thing, but only if you set aside time to declutter. It may not be fun at the moment, but it is a lot more fun than spending 30 minutes digging through junk to find the right paint or an old sketch.\n",
      "\n",
      "\n",
      "Don't be sentimental here. If you haven't used it in the last six months there is little chance you'll use it in the next six months. Toss it.\n",
      " Example of Summary:  Keep related supplies in the same area.\n",
      "Make an effort to clean a dedicated workspace after every session.\n",
      "Place loose supplies in large, clearly visible containers.\n",
      "Use clotheslines and clips to hang sketches, photos, and reference material.\n",
      "Use every inch of the room for storage, especially vertical space.\n",
      "Use chalkboard paint to make space for drafting ideas right on the walls.\n",
      "Purchase a label maker to make your organization strategy semi-permanent.\n",
      "Make a habit of throwing out old, excess, or useless stuff each month.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Load Data from NLP Library\n",
    "from nlp import load_dataset\n",
    "dataset = load_dataset('wikihow', 'all', data_dir='data')\n",
    "print(dataset.keys())\n",
    "print(\"Size of train dataset: \", dataset['train'].shape)\n",
    "print(\"Size of Validation dataset: \", dataset['validation'].shape)\n",
    "## Look at Sample Examples\n",
    "print(dataset['train'][0].keys())\n",
    "print(\" Example of text: \", dataset['train'][0]['text'])\n",
    "print(\" Example of Summary: \", dataset['train'][0]['headline'])\n",
    "## Estimate Average Length of Text and Summary\n",
    "tiny_dataset = dataset['train'].select(list(range(0, 100)))\n",
    "text_len = []\n",
    "summary_len=[]\n",
    "for i in range(len(tiny_dataset)):\n",
    "    example = tiny_dataset[i]\n",
    "    text_example = example['text']\n",
    "    text_example = text_example.replace('\\n','')\n",
    "    text_words = text_example.split()\n",
    "    text_len.append(len(text_words))\n",
    "    summary_example = example['headline']\n",
    "    summary_example = summary_example.replace('\\n','')\n",
    "    summary_words = summary_example.split()\n",
    "    summary_len.append(len(summary_words))\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(text_len)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "901826a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfbb5474",
   "metadata": {},
   "outputs": [],
   "source": [
    "class wikihow(Dataset):\n",
    "    def __init__(self, tokenizer, type_path, num_samples, input_length, output_length, print_text=False):         \n",
    "        self.dataset =  load_dataset('wikihow', 'all', data_dir='data/', split=type_path)\n",
    "        if num_samples:\n",
    "            self.dataset = self.dataset.select(list(range(0, num_samples)))\n",
    "        self.input_length = input_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.output_length = output_length\n",
    "        self.print_text = print_text\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        text = text.replace('Example of text:', '')\n",
    "        text = text.replace('Example of Summary:', '')\n",
    "        text = text.replace('\\n','')\n",
    "        text = text.replace('``', '')\n",
    "        text = text.replace('\"', '')\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    \n",
    "    def convert_to_features(self, example_batch):\n",
    "        # Tokenize contexts and questions (as pairs of inputs)\n",
    "        \n",
    "        if self.print_text:\n",
    "            print(\"Input Text: \", self.clean_text(example_batch['text']))\n",
    "#         input_ = self.clean_text(example_batch['text']) + \" </s>\"\n",
    "#         target_ = self.clean_text(example_batch['headline']) + \" </s>\"\n",
    "        \n",
    "        input_ = self.clean_text(example_batch['text'])\n",
    "        target_ = self.clean_text(example_batch['headline'])\n",
    "        \n",
    "        source = self.tokenizer.batch_encode_plus([input_], max_length=self.input_length, \n",
    "                                                     padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "        \n",
    "        targets = self.tokenizer.batch_encode_plus([target_], max_length=self.output_length, \n",
    "                                                     padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "    \n",
    "       \n",
    "        return source, targets\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        source, targets = self.convert_to_features(self.dataset[index])\n",
    "        \n",
    "        source_ids = source[\"input_ids\"].squeeze()\n",
    "        target_ids = targets[\"input_ids\"].squeeze()\n",
    "\n",
    "        src_mask    = source[\"attention_mask\"].squeeze()\n",
    "        target_mask = targets[\"attention_mask\"].squeeze()\n",
    "\n",
    "        return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e99e73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5FineTuner(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super(T5FineTuner, self).__init__()\n",
    "        self.hparams = hparams        \n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(hparams.model_name_or_path)\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(hparams.tokenizer_name_or_path)\n",
    "        self.rouge_metric = load_metric('rouge') \n",
    "        \n",
    "        if self.hparams.freeze_embeds:\n",
    "            self.freeze_embeds()\n",
    "        if self.hparams.freeze_encoder:\n",
    "            self.freeze_params(self.model.get_encoder())\n",
    "            assert_all_frozen(self.model.get_encoder())\n",
    "            \n",
    "            \n",
    "        n_observations_per_split = {\n",
    "            \"train\": self.hparams.n_train,\n",
    "            \"validation\": self.hparams.n_val,\n",
    "            \"test\": self.hparams.n_test,\n",
    "        }\n",
    "        self.n_obs = {k: v if v >= 0 else None for k, v in n_observations_per_split.items()}\n",
    "        \n",
    "    \n",
    "    def freeze_params(self, model):\n",
    "        for par in model.parameters():\n",
    "            par.requires_grad = False\n",
    "            \n",
    "            \n",
    "    def freeze_embeds(self):\n",
    "        \"\"\"Freeze token embeddings and positional embeddings for bart, just token embeddings for t5.\"\"\"\n",
    "        try:\n",
    "            self.freeze_params(self.model.model.shared)\n",
    "            for d in [self.model.model.encoder, self.model.model.decoder]:\n",
    "                freeze_params(d.embed_positions)\n",
    "                freeze_params(d.embed_tokens)\n",
    "        except AttributeError:\n",
    "            self.freeze_params(self.model.shared)\n",
    "            for d in [self.model.encoder, self.model.decoder]:\n",
    "                self.freeze_params(d.embed_tokens)\n",
    "    \n",
    "    def lmap(self, f, x):\n",
    "        \"\"\"list(map(f, x))\"\"\"\n",
    "        return list(map(f, x))\n",
    "    \n",
    "\n",
    "    def is_logger(self):\n",
    "        return self.trainer.proc_rank <= 0\n",
    "    \n",
    "    \n",
    "    def parse_score(self, result):\n",
    "        return {k: round(v.mid.fmeasure * 100, 4) for k, v in result.items()}\n",
    "        \n",
    "    def forward(\n",
    "      self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, lm_labels=None\n",
    "  ):\n",
    "        return self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            lm_labels=lm_labels,\n",
    "    )\n",
    "\n",
    "    def _step(self, batch):\n",
    "        lm_labels = batch[\"target_ids\"]\n",
    "        lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        outputs = self(\n",
    "            input_ids=batch[\"source_ids\"],\n",
    "            attention_mask=batch[\"source_mask\"],\n",
    "            lm_labels=lm_labels,\n",
    "            decoder_attention_mask=batch['target_mask']\n",
    "        )\n",
    "\n",
    "        loss = outputs[0]\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def ids_to_clean_text(self, generated_ids):\n",
    "        gen_text = self.tokenizer.batch_decode(\n",
    "            generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "        )\n",
    "        return self.lmap(str.strip, gen_text)\n",
    "    \n",
    "    \n",
    "    def _generative_step(self, batch) :\n",
    "        \n",
    "        t0 = time.time()\n",
    "        \n",
    "        generated_ids = self.model.generate(\n",
    "            batch[\"source_ids\"],\n",
    "            attention_mask=batch[\"source_mask\"],\n",
    "            use_cache=True,\n",
    "            decoder_attention_mask=batch['target_mask'],\n",
    "            max_length=150, \n",
    "            num_beams=2,\n",
    "            repetition_penalty=2.5, \n",
    "            length_penalty=1.0, \n",
    "            early_stopping=True\n",
    "        )\n",
    "        preds = self.ids_to_clean_text(generated_ids)\n",
    "        target = self.ids_to_clean_text(batch[\"target_ids\"])\n",
    "            \n",
    "        gen_time = (time.time() - t0) / batch[\"source_ids\"].shape[0]  \n",
    "    \n",
    "        loss = self._step(batch)\n",
    "        base_metrics = {'val_loss': loss}\n",
    "#         rouge: Dict = self.calc_generative_metrics(preds, target)\n",
    "        summ_len = np.mean(self.lmap(len, generated_ids))\n",
    "        base_metrics.update(gen_time=gen_time, gen_len=summ_len, preds=preds, target=target)\n",
    "        self.rouge_metric.add_batch(preds, target)\n",
    "        \n",
    "#         rouge_results = self.rouge_metric.compute() \n",
    "#         rouge_dict = self.parse_score(rouge_results)\n",
    "#         base_metrics.update(rouge1=rouge_dict['rouge1'], rougeL=rouge_dict['rougeL'])\n",
    "        \n",
    "        return base_metrics\n",
    "    \n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "\n",
    "        tensorboard_logs = {\"train_loss\": loss}\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "  \n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_train_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        tensorboard_logs = {\"avg_train_loss\": avg_train_loss}\n",
    "        return {\"avg_train_loss\": avg_train_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._generative_step(batch)\n",
    "    \n",
    "  \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        \n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        tensorboard_logs = {\"val_loss\": avg_loss}\n",
    "        \n",
    "        rouge_results = self.rouge_metric.compute() \n",
    "        rouge_dict = self.parse_score(rouge_results)\n",
    "    \n",
    "        tensorboard_logs.update(rouge1=rouge_dict['rouge1'], rougeL=rouge_dict['rougeL'])\n",
    "        \n",
    "        ## Clear out the lists for next epoch\n",
    "        self.target_gen= []\n",
    "        self.prediction_gen=[]\n",
    "        return {\"avg_val_loss\": avg_loss, \n",
    "                \"rouge1\" : rouge_results['rouge1'],\n",
    "                \"rougeL\" : rouge_results['rougeL'],\n",
    "                \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
    "\n",
    "        model = self.model\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": self.hparams.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon)\n",
    "        self.opt = optimizer\n",
    "        return [optimizer]\n",
    "  \n",
    "    def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx, second_order_closure=None, using_native_amp=False):\n",
    "        if self.trainer.use_tpu:\n",
    "            xm.optimizer_step(optimizer)\n",
    "        else:\n",
    "            optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        self.lr_scheduler.step()\n",
    "  \n",
    "    def get_tqdm_dict(self):\n",
    "        tqdm_dict = {\"loss\": \"{:.3f}\".format(self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n",
    "\n",
    "        return tqdm_dict\n",
    "    \n",
    "\n",
    "    def train_dataloader(self):   \n",
    "        n_samples = self.n_obs['train']\n",
    "        train_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"train\", num_samples=n_samples, args=self.hparams)\n",
    "        dataloader = DataLoader(train_dataset, batch_size=self.hparams.train_batch_size, drop_last=True, shuffle=True, num_workers=4)\n",
    "        t_total = (\n",
    "            (len(dataloader.dataset) // (self.hparams.train_batch_size * max(1, self.hparams.n_gpu)))\n",
    "            // self.hparams.gradient_accumulation_steps\n",
    "            * float(self.hparams.num_train_epochs)\n",
    "        )\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            self.opt, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=t_total\n",
    "        )\n",
    "        self.lr_scheduler = scheduler\n",
    "        return dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        n_samples = self.n_obs['validation']\n",
    "        validation_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"validation\", num_samples=n_samples, args=self.hparams)\n",
    "        \n",
    "        return DataLoader(validation_dataset, batch_size=self.hparams.eval_batch_size, num_workers=4)\n",
    "    \n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        n_samples = self.n_obs['test']\n",
    "        test_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"test\", num_samples=n_samples, args=self.hparams)\n",
    "        \n",
    "        return DataLoader(test_dataset, batch_size=self.hparams.eval_batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "754c4507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Summarized text: \n",
      " Drink water.Eat yogurt.Eat fibrous fruits and vegetables.Try teas.Eat lactose-intolerant foods.Eat sugar-free gum.Drink plenty of water.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deep-learning-analytics/wikihow-t5-small\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"deep-learning-analytics/wikihow-t5-small\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "text = \"\"\"\"\n",
    "Lack of fluids can lead to dry mouth, which is a leading cause of bad breath. Water\n",
    "can also dilute any chemicals in your mouth or gut that are causing bad breath., Studies show that\n",
    "eating 6 ounces of yogurt a day reduces the level of odor-causing compounds in the mouth. In\n",
    "particular, look for yogurt containing the active bacteria Streptococcus thermophilus or\n",
    "Lactobacillus bulgaricus., The abrasive nature of fibrous fruits and vegetables helps to clean\n",
    "teeth, while the vitamins, antioxidants, and acids they contain improve dental health.Foods that can\n",
    "be particularly helpful include:Apples — Apples contain vitamin C, which is necessary for health\n",
    "gums, as well as malic acid, which helps to whiten teeth.Carrots — Carrots are rich in vitamin A,\n",
    "which strengthens tooth enamel.Celery — Chewing celery produces a lot of saliva, which helps to\n",
    "neutralize bacteria that cause bad breath.Pineapples — Pineapples contain bromelain, an enzyme that\n",
    "cleans the mouth., These teas have been shown to kill the bacteria that cause bad breath and\n",
    "plaque., An upset stomach can lead to burping, which contributes to bad breath. Don’t eat foods that\n",
    "upset your stomach, or if you do, use antacids. If you are lactose intolerant, try lactase tablets.,\n",
    "They can all cause bad breath. If you do eat them, bring sugar-free gum or a toothbrush and\n",
    "toothpaste to freshen your mouth afterwards., Diets low in carbohydrates lead to ketosis — a state\n",
    "in which the body burns primarily fat instead of carbohydrates for energy. This may be good for your\n",
    "waistline, but it also produces chemicals called ketones, which contribute to bad breath.To stop the\n",
    "problem, you must change your diet. Or, you can combat the smell in one of these ways:Drink lots of\n",
    "water to dilute the ketones.Chew sugarless gum or suck on sugarless mints.Chew mint leaves.\n",
    "\"\"\"\n",
    "\n",
    "preprocess_text = text.strip().replace(\"\\n\",\"\")\n",
    "tokenized_text = tokenizer.encode(preprocess_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "summary_ids = model.generate(\n",
    "            tokenized_text,\n",
    "            max_length=150, \n",
    "            num_beams=2,\n",
    "            repetition_penalty=2.5, \n",
    "            length_penalty=1.0, \n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print (\"\\n\\nSummarized text: \\n\",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c812743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
