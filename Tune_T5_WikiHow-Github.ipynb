{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T18:48:47.482217Z",
     "start_time": "2020-09-02T18:48:47.245642Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ravy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import re\n",
    "from itertools import chain\n",
    "from string import punctuation\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from nlp import load_metric\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up WandB for your project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Find detailed error logs at: C:\\Users\\ravy\\AppData\\Local\\Temp\\debug-cli.log\n",
      "Error: api_key not configured (no-tty). call wandb login [your_api_key]\n"
     ]
    }
   ],
   "source": [
    "## Login to WandB and get your API Key\n",
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T18:48:47.486121Z",
     "start_time": "2020-09-02T18:48:47.483336Z"
    }
   },
   "outputs": [],
   "source": [
    "## Paste your API key in the YOUR_API_KEY variable below\n",
    "import wandb\n",
    "YOUR_API_KEY = ''\n",
    "os.environ[\"WANDB_API_KEY\"] = YOUR_API_KEY\n",
    "wandb_logger = WandbLogger(project='wikohow-t5')\n",
    "# wandb.init(project=\"transformers_tutorials_summarization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data using NLP Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T18:48:47.865252Z",
     "start_time": "2020-09-02T18:48:47.487297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0n1xus/codexglue, 0n1xus/pytorrent-standalone, AConsApart/anime_subtitles_DialoGPT, AI-Sweden/SuperLim, AI-it/khs_service_test, AI-it/korean-hate-speech, ARKseal/YFCC14M_subset_webdataset, ARTeLab/fanpage, ARTeLab/ilpost, ARTeLab/mlsum-it, Abdo1Kamr/Arabic_Hadith, Abirate/english_quotes, Abirate/french_book_reviews, AdWeeb/DravidianMT, Adnan/Urdu_News_Headlines, Aisha/BAAD16, Aisha/BAAD6, Akshith/aa, Akshith/g_rock, Akshith/test, AlekseyDorkin/extended_tweet_emojis, AlexMaclean/all-deletion-compressions, AlexMaclean/wikipedia-deletion-compressions, AlexZapolskii/zapolskii-amazon, AlgoveraAI/CryptoPunks, Aliseyfi/event_token_type, Alvenir/nst-da-16khz, Annielytics/DoctorsNotes, Anurag-Singh-creator/task, Anurag-Singh-creator/tasks, AryanLala/autonlp-data-Scientific_Title_Generator, Avishekavi/Avi, BSC-TeMU/SQAC, BSC-TeMU/ancora-ca-ner, BSC-TeMU/sts-ca, BSC-TeMU/tecla, BSC-TeMU/viquiquad, BSC-TeMU/xquad-ca, Babelscape/rebel-dataset, Babelscape/wikineural, Binbin/my_dataset, BlakesOrb6/Fred-Flintstone, Bosio/pacman, Bosio/pacman_descriptions, CAGER/rick, CALM/arwiki, CAiRE/ASCEND, CShorten/KerasBERT, CShorten/ZillowPrize, ChadxxxxHall/Inter-vision, Champion/vpc2020_clear_anon_speech, Charitarth/SemEval2014-Task4, Check/a_re_gi, Check/region_1, Check/region_2, Check/region_3, Check/region_4, Check/region_5, Check/region_6, Check/region_7, Check/region_8, Check/region_9, Check/regions, Check/vverify, ChineseDatasets/tnews, ChristophSchuhmann/MS_COCO_2017_URL_TEXT, Chun/dataset, Chuu/Vhh, CodedotAI/code-clippy-tfrecords, CodedotAI/code_clippy, Cropinky/flatearther, Cropinky/rap_lyrics_english, Cropinky/wow_fishing_bobber, Cyberfish/pos_tagger, Cyberfish/text_error_correction, DDSC/angry-tweets, DDSC/dkhate, DDSC/europarl, DDSC/lcc, DDSC/partial-danish-gigaword-no-twitter, DDSC/reddit-da, DDSC/squad-da, DDSC/twitter-sent, DELith/github-issues, DSCI511G1/COP26_Energy_Transition_Tweets, Daniele/dante-corpus, Darren/data, Datatang/accented_english, Datatang/accented_mandarin, Datatang/chinese_dialect, Datatang/mandarin_chinese, Datatang/mixed_speech_chinese_english, Datatang/multi_language, Datatang/multi_language_conversation, Davlan/conll2003_de_noMISC, Davlan/conll2003_noMISC, Davlan/masakhanerV1, DelgadoPanadero/Pokemon, DeskDown/ALTDataset_en-to-fil-vi-id-ms-ja-khm, Dmitriy612/1, DoctorSlimm/yipee, Doohae/modern_music_re, EMBO/biolang, EMBO/sd-nlp, ESZER/H, Emanuel/UD_Portuguese-Bosque, Emon/sobuj, Enes3774/data, Exr0n/wiki-entity-similarity, Eymen3455/xsum_tr, FL33TW00D/test-dataset, FRTNX/cosuju, FRTNX/worldbank-projects, Felix-ML/quoteli3, Fhrozen/JTubeSpeech, Finnish-NLP/mc4_fi_cleaned, Firoj/CrisisBench, Francois/futures_es, Fraser/mnist-text-default, Fraser/mnist-text-no-spaces, Fraser/mnist-text-small, Fraser/news-category-dataset, Fraser/python-lines, Fraser/short-jokes, Fraser/wiki_sentences, GEM/ART, GEM/BiSECT, GEM/CrossWOZ, GEM/OrangeSum, GEM/RiSAWOZ, GEM/RotoWire_English-German, GEM/SIMPITIKI, GEM/SciDuet, GEM/Taskmaster, GEM/cochrane-simplification, GEM/common_gen, GEM/conversational_weather, GEM/cs_restaurants, GEM/dart, GEM/dstc10_track2_task2, GEM/e2e_nlg, GEM/indonlg, GEM/mlb_data_to_text, GEM/mlsum, GEM/opusparcus, GEM/references, GEM/schema_guided_dialog, GEM/split_and_rephrase, GEM/sportsett_basketball, GEM/squad_v2, GEM/surface_realisation_st_2020, GEM/totto, GEM/turku_hockey_data2text, GEM/turku_paraphrase_corpus, GEM/viggo, GEM/web_nlg, GEM/wiki_auto_asset_turk, GEM/wiki_cat_sum, GEM/wiki_lingua, GEM/xlsum, GEM/xsum, Gabriel/squad_v2_sv, GalacticAI/Noirset, Gauravadlakha1509/new_one, Graphcore/wikipedia-bert-128, Graphcore/wikipedia-bert-512, Gwangho/NCBI-Sars-Cov-2, HHousen/ParaSCI, HHousen/msrp, HHousen/quora, Halilyesilceng/autonlp-data-nameEntityRecognition, HarleyQ/WitcherDialogue, Harveenchadha/bol-models, Harveenchadha/indic-kenlm-language-models, Harveenchadha/indoml-toxic, Harveenchadha/indoml, Harveenchadha/vish-toxic-indic, HarveyBWest/mybot, Hellisotherpeople/DebateSum, HenryAI/KerasAPIReference.txt, HenryAI/KerasBERTv1-Data, HenryAI/KerasCodeExamples.txt, HenryAI/KerasDeveloperGuides.txt, Husain/intent-classification-en-fr, IFSTalfredoswald/MBTI, IGESML/pubmed_neg, Iftoo95/Arabic_Sentiment_and_Topics, IlyaGusev/gazeta, IlyaGusev/headline_cause, Intel/WEC-Eng, Ishwar/Senti, JIsanan/war-ceb-wikipedia, Jack0508/TED2020_kor, Jack0508/TED2020_vi, Jack0508/TED2020vi_kor, Jack0508/demo, Jack0508/eng_vi_demo, Jack0508/test, Jack0508/vi-ko-TED-txt, Jean-Baptiste/wikiner_fr, Jeska/autonlp-data-vaccinfaq, Jeska/vaccinchat, JesseParvess/book_snippets_asr, Jikiwa/demo1, Jikiwa/demo2, Jikiwa/demo3, Jikiwa/demo4, Jikiwa/glue-mnli-train, Jikiwa/push-to-hub, Jikiwa/pushe-to-hub, Jikiwa/pushed-to-hub, Jikiwa/pushedd-to-hub, Jikiwa/random_repo, Jikiwa/stargazers, Jikiwa/temp-repo-valid, Jikiwa/test-16336477963335, Jikiwa/test-16336478042515, Jikiwa/test-16336479967338, Jikiwa/test-16336480189315, Jikiwa/test-16336486877862, Jikiwa/test-16340052901609, Jikiwa/test-16340052972855, Jikiwa/test-16344347220590, Jikiwa/test-16344347234752, Jikiwa/test-16344349332219, Jikiwa/test-16344349440339, Jikiwa/test-16344351925697, Jikiwa/test-16344360501144, Jikiwa/test-16344361893586, Jikiwa/test-16344362261113, Jikiwa/test-16344362895458, Jikiwa/test-16344364230608, Jikiwa/test-16344364547167, Jikiwa/test-16344367190179, Jikiwa/test-16344368182003, JonathanSum/github-issues, KBLab/suc3, KETI-AIR/aihub, KETI-AIR/klue, KETI-AIR/kor_corpora, KETI-AIR/korquad, KETI-AIR/nikl, Karavet/ARPA-Armenian-Paraphrase-Corpus, Karavet/ILUR-news-text-classification-corpus, Karavet/pioNER-Armenian-Named-Entity, Khanoooo/autonlp-data-Corona, Khondoker/SentNoB, LIAMF-USP/arc-retrieval-c4, Langame/waiting-messages, Lenn/github-issues, LeoCordoba/CC-NEWS-ES-titles, LeoCordoba/CC-NEWS-ES, Linda/test1111, LoganKells/amazon_product_reviews_video_games, Lucylulu/amazon, Lucylulu/imdb, Lumos/yahoo_hga, MBAH/MOVIESON, MKK/Dhivehi-English, Mansooreh/sharif-emotional-speech-dataset, MarianaSahagun/test, MarkusDressel/cord, Marzipan/QA4PC, Mateo/test_dataset, Mateo/testdataset, McGill-NLP/mlquestions, Mcy/random_uselesstestsequence, Melinoe/TheLabTexts, MickyMike/large_c_corpus, Motahar/github-issues, Mrleo1nid/Test_ru_dataset, Mulin/my_second_dataset, Mulin/my_third_dataset, NLPC-UOM/English-Tamil-Parallel-Corpus, NTUYG/RAGTest, NahedAbdelgaber/evaluating-student-writing, Narsil/asr_dummy, Narsil/conversational_dummy, Narsil/image_dummy, Nathanael/NPS, NbAiLab/NCC, NbAiLab/NCC_small_100, NbAiLab/NCC_small_divided, NbAiLab/bokmaal_admin, NbAiLab/norec_agg, NbAiLab/norne, NbAiLab/norwegian_parliament, NikolajW/NPS_nonNormalized-Cased, Ofrit/tmp, Omar2027/caner_replicate, OmarN121/train, PDJ107/riot-data, Pengfei/asfwe, Pengfei/test, Pengfei/test1, Perkhad/corejur, PlanTL-GOB-ES/SQAC, Pongsaky/Wiki_SCG, Pratik/Gujarati_OpenSLR, Pyke/patent_abstract, QA/abk-eng, RBG-AI/CoRePooL, Recognai/ag_news_corrected_labels, Recognai/corrected_labels_ag_news, Remesita/tagged_reviews, Renukswamy/Patent_sentiment_analysis, RohanAiLab/persian_blog, RohanAiLab/persian_daily_news, RohanAiLab/persian_news_dataset, Romrawin/mn-sim, SCourthial/test, Sabokou/qg_squad_modified, Sabokou/qg_squad_modified_dev, SajjadAyoubi/persian_qa, Sam2021/Arguement_Mining_CL2017, Samip/func, SaulLu/Natural_Questions_HTML, SaulLu/Natural_Questions_HTML_Toy, SaulLu/Natural_Questions_HTML_reduced_all, SaulLu/test, SaulLu/toy_struc_dataset, SebastianS/github-issues, SergeiGKS/wikiner_fr_job, Serhii/Custom_SQuAD, SetFit/TREC-QC, SetFit/sst2, SetFit/sst5, Shahm/my_dataset, Shahm/test, Shanna/Jamaica, ShinyQ/PPKM_Pemerintah, Shushant/NepaliSentiment, Shushant/nepali, Smiling/webnovels-en, SoLID/shellcode_i_a32, SocialGrep/one-million-reddit-confessions, SocialGrep/one-million-reddit-jokes, SocialGrep/one-million-reddit-questions, SocialGrep/one-year-of-r-india, SocialGrep/reddit-crypto-aug-2021, SocialGrep/reddit-nonewnormal-complete, SocialGrep/reddit-wallstreetbets-aug-2021, SocialGrep/ten-million-reddit-answers, SocialGrep/the-reddit-covid-dataset, SophieTr/reddit_clean, TRoboto/masc, TaahaKazi/FCE, Tatyana/ru_sentiment_dataset, Terry0107/RiSAWOZ, Tevatron/msmarco-passage-corpus, Tevatron/msmarco-passage, Tevatron/scifact-corpus, Tevatron/scifact, Tevatron/wikipedia-curated-corpus, Tevatron/wikipedia-curated, Tevatron/wikipedia-nq-corpus, Tevatron/wikipedia-nq, Tevatron/wikipedia-squad-corpus, Tevatron/wikipedia-squad, Tevatron/wikipedia-trivia-corpus, Tevatron/wikipedia-trivia, Tevatron/wikipedia-wq-corpus, Tevatron/wikipedia-wq, TheBlindBandit/SpongeNot, TimTreasure4/Test, Trainmaster9977/957, Trainmaster9977/zbakuman, TristanBehrens/js-fakes-4bars, TurkuNLP/register_mc4, TurkuNLP/register_oscar, TurkuNLP/turku_hockey_data2text, TurkuNLP/turku_paraphrase_corpus, Tyler/wikimatrix_collapsed, Usin2705/test, VJGamer/test, VadorMazer/skyrimdialogstest, Valahaar/wsdmt, Vishva/UniFAQ_DataSET, Wiedy/be, Wiedy/wav2vec2-large-xls-r-300m-tr-colab, Wikidepia/IndoParaCrawl, Wikidepia/IndoSQuAD, Wikidepia/mc4-filter, Wuhu0/output, WyrdCurt/AO4W, XiangPan/iflytek, XiangPan/snli_break, XiangXiang/clt, Xinghua/test, Yatoro/github-issues, Yatoro/github_issues, Yeva/arm-summary, Yves/fhnw_swiss_parliament, Zaid/coqa_expanded, Zaid/quac_expanded, Zoe10/ner_dataset, abhishek/autonlp-data-imdb_eval, abhishek/autonlp-data-prodigy-10, abidlabs/test-image-classifier-dataset, abidlabs/test-translation-dataset, abwicke/C-B-R, abwicke/koplo, adalbertojunior/punctuation-ptbr, adamlin/FewShotWoz, adamlin/companion, adamlin/coqa_squad, adamlin/daily_dialog, adamlin/domain_classification, adamlin/multiwoz_dst, adamlin/qa_verification, adamlin/roc_story, adamlin/rs, adamlin/weibo_ner, addy88/nq-question-answeronly, addy88/sanskrit-asr-84-eval, addy88/sanskrit-asr-84, ai4bharat/samanantar, ajmbell/test-dataset, akumar33/manufacturing, albertvillanova/carbon_24, albertvillanova/datasets-tests-compression, albertvillanova/dummy_libri2mix, albertvillanova/legal_contracts, albertvillanova/multilingual_spoken_words, albertvillanova/pmc_open_access, albertvillanova/sat, albertvillanova/tests-public-raw-jsonl, albertvillanova/tests-raw-jsonl, albertvillanova/tmp-tests-zip, albertvillanova/tmp-tests, albertvillanova/vietnamese_students_feedback, alireza655/alireza655, alittleie/mis_238, allegro/klej-allegro-reviews, allegro/klej-cbd, allegro/klej-cdsc-e, allegro/klej-cdsc-r, allegro/klej-dyk, allegro/klej-nkjp-ner, allegro/klej-polemo2-in, allegro/klej-polemo2-out, allegro/klej-psc, allegro/polish-question-passage-pairs, allegro/summarization-allegro-articles, allegro/summarization-polish-summaries-corpus, allenai/c4, allenai/scico, alperbayram/TwitterDuygu, alvp/autonlp-data-alberti-stanza-names, alvp/autonlp-data-alberti-stanzas-finetuning, ami-wav2vec2/ami_multi_headset_segmented_and_chunked, ami-wav2vec2/ami_multi_headset_segmented_and_chunked_and_concatenated, ami-wav2vec2/ami_multi_headset_segmented_and_chunked_dummy, ami-wav2vec2/ami_single_headset_segmented, ami-wav2vec2/ami_single_headset_segmented_and_chunked, ami-wav2vec2/ami_single_headset_segmented_and_chunked_and_concatenated, ami-wav2vec2/ami_single_headset_segmented_and_chunked_dummy, ami-wav2vec2/ami_single_headset_segmented_dummy, animesh/autonlp-data-peptides, anton-l/common_language, anton-l/superb, anton-l/superb_demo, anton-l/superb_dummy, anukaver/EstQA, arjunth2001/online_privacy_qna, artyeth/Dorian, aseifert/merlin, aseifert/pie-synthetic, ashish-shrivastava/dont-know-dataset, ashraq/dhivehi-corpus, asi/wikitext_fr, asoroa/bsbasque, astarostap/antisemitic-tweets, astarostap/antisemitic_tweets, astarostap/autonlp-data-antisemitism-2, astrideducation/cefr-combined-no-cefr-test, atelders/politweets, athar/QA, athivvat/thai-rap-lyrics, ausgequetschtem/jtrddfhfgh, austin/rheum_abstracts, avadesian/dddd, bavard/personachat_truecased, beacon/test, bemanningssitua/dplremjfjfj, benjaminbeilharz/librivoxdeen, berkergurcay/2020-10K-Reports, bertin-project/mc4-es-sampled, bertin-project/mc4-sampling, bhadresh-savani/web_split, bhavnicksm/sentihood, bigscience/LanguageResourceCatalogue, bigscience/P3, bigscience/mc4-sampled, bigscience/open_subtitles_monolingual, biu-nlp/qa_align, biu-nlp/qa_discourse, biu-nlp/qa_srl2018, biu-nlp/qa_srl2020, biu-nlp/qamr, biu-nlp/qanom, blinoff/medical_qa_ru_data, bondarchukb/autonlp-data-iab_classification, braincode/braincode, brunodorneles/ner, bs-modeling-metadata/OSCAR_Entity_13_000, bs-modeling-metadata/c4-en-reduced-10000-with-metadata, bs-modeling-metadata/c4-en-reduced-10000, bs-modeling-metadata/c4-en-reduced-with-metadata, bs-modeling-metadata/c4-en-reduced, bs-modeling-metadata/c4-extraction-dev-v0, bs-modeling-metadata/c4_newslike_url_only, bs-modeling-metadata/html-enwiki-200806-extract-raw, bs-modeling-metadata/openwebtext-html-cc, bs-modeling-metadata/website_metadata_c4, bs-modeling-metadata/wiki_dump, bsc/ancora-ca-ner, bsc/sts-ca, bsc/tecla, bsc/viquiquad, bsc/xquad-ca, bwu2018/anime-tagging-dataset, caca/zscczs, cakiki/args_me, cakiki/paperswithcode, caltonji/harrypotter_squad_v2, caltonji/harrypotter_squad_v2_2, canwenxu/dogwhistle, cassandra-themis/QR-AN, castorini/afriberta, castorini/mr-tydi-corpus, castorini/mr-tydi, castorini/msmarco_v1_doc_doc2query-t5_expansions, castorini/msmarco_v1_doc_segmented_doc2query-t5_expansions, castorini/msmarco_v1_passage_doc2query-t5_expansions, castorini/msmarco_v2_doc_doc2query-t5_expansions, castorini/msmarco_v2_doc_segmented_doc2query-t5_expansions, castorini/msmarco_v2_passage_doc2query-t5_expansions, caythuoc/caoduoclieu, cbrew475/hwu66, ccccccc/hdjw_94ejrjr, ccdv/arxiv-classification, ccdv/arxiv-summarization, ccdv/cnn_dailymail, ccdv/govreport-summarization, ccdv/patent-classification, ccdv/pubmed-summarization, cdleong/piglatin-mt, cdleong/temp_africaNLP_keyword_spotting_for_african_languages, cdminix/iwslt2011, cdminix/mgb1, cem/dnm, cem/film, cemigo/taylor_vs_shakes, cemigo/test-data, cestwc/adapted-msrcomp, cestwc/adapted-paranmt5m, cestwc/adapted-sentcomp, cestwc/adapted-synonym, cestwc/adapted-wikismall, cestwc/adapted-wordnet, cestwc/cnn_dailymail-metaeval100, cestwc/cnn_dailymail-test50, cestwc/sac-approx-1, cestwc/sac-na, cestwc/sac, cgarciae/point-cloud-mnist, cgarciae/point_cloud_mnist, chenghao/mc4_eu_dedup, chenghao/mc4_sw_dedup, chenghao/scielo_books, chenyuxuan/wikigold, cheulyop/dementiabank, cheulyop/ksponspeech, chitra/contradictionNLI, chopey/dhivehi, clarin-pl/aspectemo, clarin-pl/cst-wikinews, clarin-pl/kpwr-ner, clarin-pl/nkjp-pos, clarin-pl/polemo2-official, classla/FRENK-hate-en, classla/FRENK-hate-hr, classla/FRENK-hate-sl, classla/copa_hr, classla/hr500k, classla/janes_tag, classla/reldi_hr, classla/reldi_sr, classla/setimes_sr, classla/ssj500k, clem/autonlp-data-french_word_detection, clips/mfaq, clips/mqa, cnrcastroli/aaaa, coala/kkk, collectivat/tv3_parla, congpt/dstc23_asr, corypaik/coda, corypaik/prost, craffel/openai_lambada, crich/cider, cristinakuo/latino40, csarron/image-captions, csebuetnlp/xlsum, csebuetnlp/xnli_bn, cstrathe435/Task2Dial, ctgowrie/chessgames, ctl/ConceptualCaptions, cyko/books, cylee/github-issues, dalle-mini/wit, dansbecker/hackernews_hiring_posts, darentang/sroie, dasago78/dasago78dataset, dataset/wikipedia_bn, davanstrien/snorkel_genre, david-wb/zeshel, davidwisdom/reddit-randomness, debatelab/aaac, deepset/germandpr, deepset/germanquad, deokgu/fooddetection, dev/untitled_imgs, dfgvhxfgv/fghghj, dfki-nlp/few-nerd, dfki-nlp/mobie, dgao/librispeech_nc_test, dgknrsln/Yorumsepeti, diiogo/brwac-clean, diiogo/harem-seletivo, diiogo/harem-total, diiogo/oscar, dispenst/jhghdghfd, dispix/test-dataset, dk-crazydiv/huggingface-modelhub, dlb/plue, dog/friends-of-mine, dog/punks, dongpil/test, dragosnicolae555/RoITD, dvilasuero/ag_news_error_analysis, dvilasuero/ag_news_training_set_losses, dvilasuero/test-dataset, dweb/squad_with_cola_scores, dynabench/dynasent, dynabench/qa, eason929/test, ebrigham/asr_files, edfews/szdfcszdf, edge2992/github-issues, edge2992/rri-short, edge2992/rri_short, edsas/fgrdtgrdtdr, edsas/grttyi, ehcalabres/ravdess_speech, ejjaffe/onion_headlines_2_sources, eliza-dukim/load_klue_re, elonmuskceo/persistent-space-dataset, emrecan/stsb-mt-turkish, enelpol/czywiesz, erikacardenas300/Zillow_Economics_Dataset, ervis/aaa, ervis/qqq, eugenesiow/BSD100, eugenesiow/Div2k, eugenesiow/PIRM, eugenesiow/Set14, eugenesiow/Set5, eugenesiow/Urban100, ewdrtfwe/54refyghrtf, fatvvs/autonlp-data-entity_model_conll2003, fengzhang/fzTestDatasets, fhamborg/news_sentiment_newsmtsc, fihtrotuld/asu, flax-community/code_clippy_data, flax-community/conceptual-12m-mbart-50-multilingual, flax-community/conceptual-12m-multilingual-marian-128, flax-community/conceptual-12m-multilingual-marian-es, flax-community/conceptual-12m-multilingual-marian, flax-community/conceptual-captions-12, flax-community/dummy-oscar-als-32, flax-community/german-common-voice-processed, flax-community/german_common_crawl, flax-community/multilingual-vqa, flax-community/norwegian-clean-dummy, flax-community/swahili-safi, flax-sentence-embeddings/Gender_Bias_Evaluation_Set, flax-sentence-embeddings/paws-jsonl, flax-sentence-embeddings/stackexchange_math_jsonl, flax-sentence-embeddings/stackexchange_title_best_voted_answer_jsonl, flax-sentence-embeddings/stackexchange_title_body_jsonl, flax-sentence-embeddings/stackexchange_titlebody_best_and_down_voted_answer_jsonl, flax-sentence-embeddings/stackexchange_titlebody_best_voted_answer_jsonl, flax-sentence-embeddings/stackexchange_xml, flexudy/OMQD, formermagic/github_python_1m, formu/CVT, fractalego/QA_to_statements, frahman/github-issues, frtna/es_it_Results-base-OPUS_Tatoeba, frtna/jwt300_mt, frtna/opensubtitles_mt, frtna/ted_mt, fulai/DuReader, fuliucansheng/minicoco, fuliucansheng/mininlp, fuliucansheng/pascal_voc, fuyun1107/clip-for-vlp, fvillena/cantemist, fvillena/spanish_diagnostics, gagan3012/fake-news, gagan3012/grover-data, gar1t/test, gayanin/pubmed-gastro-maskfilling, gayanin/pubmed-gastro-paraphrasing, gayanin/pubmed-gastro-summarisation, gcaillaut/citeseer, gcaillaut/cora, gcaillaut/pubmed, geekydevu/mlquestions, german-nlp-group/german_common_crawl, gmnlp/tico19, gpt3mix/rt20, gpt3mix/sst2, gsarti/change_it, gsarti/clean_mc4_it, gsarti/flores_101, gsarti/itacola, gsarti/wmt_vat, gustavecortal/fr_covid_news, gusu/mymodel1, habu24/fdz, hartzeer/kdfjdshfje, henrychess/gutenberg-fulltext-dirty-locc, herbievore/test, hf-internal-testing/cats_vs_dogs_sample, hf-internal-testing/fixtures_ade20k, hf-internal-testing/fixtures_docvqa, hf-internal-testing/fixtures_image_utils, hf-internal-testing/fixtures_nlvr2, hf-internal-testing/fixtures_ocr, hf-internal-testing/fixtures_sintel, hf-internal-testing/librispeech_asr_demo, hf-internal-testing/librispeech_asr_dummy, hf-internal-testing/test-dataset, hf-internal-testing/transformers-metadata, hfface/poopi, holodata/sensai, holylovenia/recam, hong/autonlp-data-zoo_test, honghungle/dataset, howardmiddleton382/esuyertusutr, howardmiddleton382/wgweagwege, huggingFaceUser02/air21_grp13_inference_results, huggingFaceUser02/air21_grp13_tokenized_results, huggingartists/100-gecs, huggingartists/21-savage, huggingartists/25-17, huggingartists/50-cent, huggingartists/5nizza, huggingartists/5opka, huggingartists/6ix9ine, huggingartists/aaron-watson, huggingartists/abba, huggingartists/adele, huggingartists/agata-christie, huggingartists/aikko, huggingartists/aimer, huggingartists/ajr, huggingartists/alan-walker, huggingartists/andre-3000, huggingartists/arash, huggingartists/architects, huggingartists/arctic-monkeys, huggingartists/ariana-grande, huggingartists/ariya, huggingartists/armin-van-buuren, huggingartists/as-i-lay-dying, huggingartists/asdfgfa, huggingartists/asper-x, huggingartists/baklan, huggingartists/big-baby-tape, huggingartists/big-russian-boss, huggingartists/bill-wurtz, huggingartists/billie-eilish, huggingartists/billy-talent, huggingartists/bladee, huggingartists/bob-dylan, huggingartists/bones, huggingartists/booker, huggingartists/boris-grebenshikov, huggingartists/braii, huggingartists/bring-me-the-horizon, huggingartists/bruce-springsteen, huggingartists/bryan-adams, huggingartists/burzum, huggingartists/bushido-zho, huggingartists/cardi-b, huggingartists/chester-bennington, huggingartists/chief-keef, huggingartists/cocomelon, huggingartists/coin, huggingartists/coldplay, huggingartists/dababy, huggingartists/david-bowie, huggingartists/ddt, huggingartists/death-grips, huggingartists/deep-purple, huggingartists/denderty, huggingartists/dermot-kennedy, huggingartists/dj-artem-artemov, huggingartists/doja-cat, huggingartists/drake, huggingartists/dua-lipa, huggingartists/duran-duran, huggingartists/dzhizus, huggingartists/ed-sheeran, huggingartists/egor-kreed, huggingartists/egor-letov, huggingartists/elton-john, huggingartists/eminem, huggingartists/enigma, huggingartists/enya, huggingartists/epic-rap-battles-of-history, huggingartists/face, huggingartists/fascinoma, huggingartists/fear-factory, huggingartists/florence-the-machine, huggingartists/freddie-dredd, huggingartists/freelancer, huggingartists/galenskaparna-and-after-shave, huggingartists/ghost, huggingartists/ghostemane, huggingartists/ghostmane, huggingartists/gizmo, huggingartists/gorillaz, huggingartists/green-day, huggingartists/grigory-leps, huggingartists/grimes, huggingartists/gspd, huggingartists/gunna, huggingartists/hillsong-worship, huggingartists/hyuna, huggingartists/i-dont-know-how-but-they-found-me, huggingartists/idktime, huggingartists/imagine-dragons, huggingartists/jah-khalib, huggingartists/jim-morrison, huggingartists/john-k-samson, huggingartists/john-lennon, huggingartists/joji, huggingartists/joni-mitchell, huggingartists/justin-bieber, huggingartists/kanye-west, huggingartists/kasta, huggingartists/katy-perry, huggingartists/kehlani, huggingartists/kendrick-lamar, huggingartists/kesha, huggingartists/king-krule, huggingartists/kipelov, huggingartists/kishlak, huggingartists/kizaru, huggingartists/kojey-radical, huggingartists/krechet, huggingartists/krept-and-konan-bugzy-malone-sl-morisson-abra-cadabra-rv-and-snap-capone, huggingartists/kurt-cobain, huggingartists/lady-gaga, huggingartists/lazy-jay, huggingartists/led-zeppelin, huggingartists/lil-baby, huggingartists/lil-nas-x, huggingartists/lil-peep, huggingartists/lil-skies, huggingartists/lil-uzi-vert, huggingartists/linkin-park, huggingartists/little-big, huggingartists/lizer, huggingartists/logic, huggingartists/lorde, huggingartists/loud-luxury, huggingartists/loverance, huggingartists/lovv66, huggingartists/lumen, huggingartists/lyapis-trubetskoy, huggingartists/macan, huggingartists/machine-gun-kelly, huggingartists/madonna, huggingartists/marillion, huggingartists/maroon-5, huggingartists/mashina-vremeni, huggingartists/mating-ritual, huggingartists/max-korzh, huggingartists/mayot, huggingartists/mc-ride, huggingartists/melanie-martinez, huggingartists/metallica, huggingartists/mf-doom, huggingartists/michael-jackson, huggingartists/mikhail-gorshenev, huggingartists/mikhail-krug, huggingartists/miyagi, huggingartists/mnogoznaal, huggingartists/morgenshtern, huggingartists/mumiy-troll, huggingartists/muse, huggingartists/nautilus-pompilius, huggingartists/nervy, huggingartists/nicki-minaj, huggingartists/nirvana, huggingartists/noize-mc, huggingartists/oasis, huggingartists/obladaet, huggingartists/og-buda, huggingartists/ot-rus, huggingartists/our-last-night, huggingartists/oxxxymiron, huggingartists/peter-paul-and-mary, huggingartists/pharaoh, huggingartists/phish, huggingartists/pink-floyd, huggingartists/placebo, huggingartists/platina, huggingartists/pop-smoke, huggingartists/post-malone, huggingartists/pyrokinesis, huggingartists/queen, huggingartists/radiohead, huggingartists/rage-against-the-machine, huggingartists/ramil, huggingartists/rammstein, huggingartists/red-hot-chili-peppers, huggingartists/rex-orange-county, huggingartists/rihanna, huggingartists/rocket, huggingartists/sam-kim, huggingartists/scriptonite, huggingartists/sektor-gaza, huggingartists/selena-gomez, huggingartists/sergei-letov, huggingartists/shadowraze, huggingartists/sia, huggingartists/sid-sriram, huggingartists/skillet, huggingartists/slava-kpss, huggingartists/slava-marlow, huggingartists/snoop-dogg, huggingartists/sqwore, huggingartists/sugar-ray, huggingartists/suicideoscope, huggingartists/sum-41, huggingartists/sundara-karma, huggingartists/system-of-a-down, huggingartists/t-fest, huggingartists/tanzy-minus, huggingartists/taylor-swift, huggingartists/tedeschi-trucks-band, huggingartists/the-69-eyes, huggingartists/the-avalanches, huggingartists/the-beatles, huggingartists/the-gazette, huggingartists/the-grateful-dead, huggingartists/the-king-and-the-jester, huggingartists/the-notorious-big, huggingartists/the-sugarcubes, huggingartists/the-the-pigs, huggingartists/the-velvet-underground, huggingartists/the-weeknd, huggingartists/tiamat, huggingartists/till-lindemann, huggingartists/tom-waits, huggingartists/tony-raut-and-garry-topor, huggingartists/tool, huggingartists/totpoc, huggingartists/travis-scott, huggingartists/twenty-one-pilots, huggingartists/tyler-the-creator, huggingartists/upsahl, huggingartists/v-x-v-prince, huggingartists/van-morrison, huggingartists/veggietales, huggingartists/viktor-tsoi, huggingartists/vladimir-vysotsky, huggingartists/xxxtentacion, huggingartists/young-thug, huggingartists/yung-lean, huggingartists/yung-plague, huggingartists/zemfira, huggingface/DataMeasurementsFiles, huggingface/documentation-images, huggingface/label-files, huggingface/transformers-metadata, huggingface-course/codeparrot-ds-train, huggingface-course/codeparrot-ds-valid, huyongquan/d2, hyeonduck/whiteboard_abuse_dataset, hyeonduck/your_dataset_name, iamshsdf/sssssssssss, iarfmoose/qa_evaluator, iarfmoose/question_generator, image-search-2/unsplash_lite_image_dataset, imthanhlv/binhvq_dedup, imthanhlv/binhvq_news21_raw, indonesian-nlp/id_personachat, iohadrubin/mtop, iohadrubin/smcalflow, jaimin/wav2vec2-large-xlsr-gujarati-demo, jakeazcona/short-text-labeled-emotion-classification, jakeazcona/short-text-multi-labeled-emotion-classification, jakemarcus/MATH, jamescalam/climate-fever-similarity, jamol1741/test_dataset, jdepoix/junit_test_completion, jglaser/binding_affinity, jhqwqq/2, jimregan/clarinpl_sejmsenat, jimregan/clarinpl_studio, jimregan/foinse, jimregan/lasid, jinmang2/KorQuADv1, jinmang2/common-sense-mrc, jinmang2/load_klue_re, jinmang2/medical-mask, jinmang2/pred, jinmang2/temp, jinmang2/vision-data, jiobiala24/demo1, jiobiala24/speech_accent, jiyoojeong/targetizer, jlh/coco, jmamou/augmented-glue-sst2, joelito/ler, joelito/sem_eval_2010_task_8, johnpaulbin/autonlp-data-asag-v2, jonfd/ICC, jozierski/ecomwebtexts-pl, jpcorb20/multidogo, jsfactory/mental_health_reddit_posts, julien-c/dummy-dataset-from-colab, julien-c/persistent-space-dataset, julien-c/reactiongif, juliensimon/autonlp-data-song-lyrics-demo, juliensimon/autonlp-data-song-lyrics, juny116/few_glue, justinqbui/covid_fact_checked_google_api, justinqbui/covid_fact_checked_polifact, k-halid/ar, k0t1k/test, kaka10/fgfgfgfg, karinev/lanuitdudroit, kartikay/review-summarizer, katoensp/VR-OP, kenlevine/CUAD, keshan/clean-si-mc4, keshan/large-sinhala-asr-dataset, keshan/multispeaker-tts-sinhala, keshan/wit-dataset, kevinassobo/sales_2015_dataset, kevinlu1248/personificationgen, khalidsaifullaah/detecThreats, khanbaba/online_love, khursani8/sani, kiamehr74/CoarseWSD-20, kiyoung2/aistage-mrc, kiyoung2/temp, kleinay/qa_srl, kmfoda/booksum, kmfoda/name_finder_v1, kmyoo/klue-tc-dev, knilakshan20/wikigold, kroshan/BioASQ, kroshan/qa_evaluator, laion/laion400m, laion/laion_100m_vqgan_f8, lara-martin/Scifi_TV_Shows, larcane/ko-WIT, laugustyniak/abusive-clauses-pl, lavis-nlp/german_legal_sentences, layboard/layboard.in, lbourdois/CoFiF, leiping/jj, leiping/teeee, leoapolonio/AMI_Meeting_Corpus, lewtun/asr-preds-test, lewtun/asr_dummy, lewtun/binary_classification_dummy, lewtun/bulk-superb-s3p-superb-49606, lewtun/drug-reviews, lewtun/gem-multi-dataset-predictions, lewtun/gem-sub-03, lewtun/gem-test-predictions, lewtun/gem-test-references, lewtun/github-issues-test, lewtun/github-issues, lewtun/mnist-preds, lewtun/my-awesome-dataset, lewtun/s3prl-sd-dummy, lewtun/text_classification_dummy, lhoestq/conll2003, lhoestq/custom_squad, lhoestq/demo1, lhoestq/squad, lhoestq/test, lhoestq/test2, lhoestq/test_zip_txt, lhoestq/tmp, lhoestq/wikipedia_bn, liam168/nlp_c4_sentiment, lidia/202111, lijingxin/github-issues, limjiayi/hateful_memes_expanded, lincoln/newsquadfr, linhd-postdata/stanzas, liweili/c4_200m, lkiouiou/o9ui7877687, lkndsjkndgskjngkjsndkj/jsjdjsdvkjvszlhdskb, lohanna/testedjkcxkf, lorsorlah/Dadedadedam, loveguruji609/dfdfsdfsdfsdfsdfsd, lucien/sciencemission, lucien/voacantonesed, lucien/wsaderfffjjjhhh, lucio/common_voice_eval, lukasmasuch/my-test-repo-3, lukasmasuch/my-test-repo-4, lukasmasuch/test-2, lukasmasuch/test-3, lukasmasuch/test, lukesjordan/worldbank-project-documents, luofengge/mydata, luofengge/testDataset, luomingshuang/GRID_audio, luomingshuang/GRID_text, luomingshuang/grid_lip_160_80, luozhouyang/dureader, luozhouyang/kgclue-knowledge, luozhouyang/question-answering-datasets, lvwerra/codeparrot-clean-train, lvwerra/codeparrot-clean-valid, lvwerra/codeparrot-clean, lvwerra/codeparrot-valid-clean-minimal, lvwerra/codeparrot-valid, lvwerra/repo-images, lysandre/my-cool-dataset, m3hrdadfi/recipe_nlg_lite, mad/IndonesiaNewsDataset, maji/npo_mission_statement_ucf, majod/CleanNaturalQuestionsDataset, makanan/umich, makarios19/neurips-paper, malay-huggingface/jelapang-padi, malay-huggingface/pembalakan, manandey/OSCAR_Entity_Toy, manandey/entity_experiments, manishk31/Demo, mariosasko/exposure_errors, mariosasko/nao, markscrivo/OddsOn, martiwey/codesearchnet-go, martiwey/codesearchnet-java, martiwey/codesearchnet-javascript, martiwey/codesearchnet-php, martiwey/codesearchnet-python, martiwey/codesearchnet-ruby, martodaniel/terere, masked-neuron/amazon, masked-neuron/ccd, masked-neuron/qb, maximedb/mcqa_light, maximedb/mfaq_light, maximedb/paws-x-all, maximedb/vaccinchat, maximedb/vaccinchat_retrieval, maximedb/wow, maxmoynan/SemEval2017-Task4aEnglish, mbateman/github-issues, medzaf/test, meghanabhange/chaii, meghanabhange/hilm141021, meghanabhange/hitalm141021, meghanabhange/hitalmsandbox, meghanabhange/talm141021, merve/coco, merve/folk-mythology-tales, merve/poetry, merve/qqp, metaeval/blimp_classification, metaeval/colors, metaeval/crowdflower, metaeval/ethics, metaeval/linguisticprobing, metaeval/recast, metalearning/kaggale-nlp-tutorial, metamong1/summarization_optimization, metopedia/autonlp-data-Multiple-Source-Language-Consensus-Reconstruction-o, michaelbenayoun/wikipedia-bert-128, microsoft/codexglue_method_generation, midas/inspec, midas/inspec_ke_tagged, midas/ldke3k_medium, midas/ldke3k_small, midas/ldkp3k_small, midas/semeval2010_ke_tagged, midas/semeval2017_ke_tagged, midas/test_ldkp, mishig/sample_images, mksaad/Arabic_news, ml6team/cnn_dailymail_nl, mldmm/glass_alloy_composition, mmcquade11-test/reuters-for-summarization-two, mmm-da/rutracker_anime_torrent_titles, mnaylor/evaluating-student-writing, mnemlaghi/widdd, morganchen1007/1215, morganchen1007/1216, morganchen1007/1216_00, morganchen1007/test_1213_00, moshew/my_raft, moumeneb1/French_arpa_lm, moxi43/github-issues, mozilla-foundation/common_voice_5_1, mr-robot/ec, mrm8488/fake-news, mrm8488/goemotions, mrojas/abbreviation, mrojas/body, mrojas/disease, mrojas/family, mrojas/finding, mrojas/medication, mrojas/procedure, mrp/Thai-Semantic-Textual-Similarity-Benchmark, msivanes/github-issues, muhtasham/autonlp-data-Doctor_DE, mulcyber/europarl-mono, munggok/mc4-id, mustafa12/db_ee, mustafa12/edaaaas, mustafa12/thors, mvarma/medwiki, nateraw/auto-cats-and-dogs, nateraw/auto-exp-2, nateraw/beans, nateraw/beans_old, nateraw/blahblah, nateraw/bulk-dummy, nateraw/cats-and-dogs, nateraw/cats_vs_dogs, nateraw/dummy-csv-dataset, nateraw/fairface, nateraw/filings-10k, nateraw/food101, nateraw/food101_old, nateraw/huggingpics-data-2, nateraw/huggingpics-data, nateraw/image-folder, nateraw/imagefolder, nateraw/imagenette, nateraw/img-demo, nateraw/rock_paper_scissors, nateraw/sync_food101, nateraw/test, nateraw/wit, nathanlsl/news, naver-clova-conversation/klue-tc-dev-tsv, naver-clova-conversation/klue-tc-tsv, naver-clova-conversation-ul/klue-tc-dev, navjordj/nak_nb, ncats/EpiClassify4GARD, ncats/EpiSet4NER, ncats/GARD_EpiSet4TextClassification, ncduy/github-issues, ncoop57/athena_data, ncoop57/csnc_human_judgement, ncoop57/rico_captions, neelalex/raft-predictions, newsha/PQuAD, nid989/FNC-1, nielsr/FUNSD_layoutlmv2, nielsr/XFUN, nielsr/funsd, nlpaueb/test, nlpconnect/dpr-nq-reader-v2, nlpconnect/dpr-nq-reader, nlpufg/brwac-pt, nlpufg/brwac, nlpufg/oscar-pt, nntadotzip/iuQAchatbot, notional/notional-python, nthngdy/bananas, ntutexas/amazon, nucklehead/ht-voice-dataset, oelkrise/CRT, osanseviero/codeparrot-train, osanseviero/llama_test, osanseviero/test, oscar-corpus/OSCAR-2109, ought/raft-submission, ought/raft, outman/test, papluca/language-identification, pariajm/sharif_emotional_speech_dataset, parivartanayurveda/Malesexproblemsayurvedictreatment, pasinit/scotus, pasinit/xlwic, patrickvonplaten/ami_single_headset_segmented_and_chunked, patrickvonplaten/common_voice_6_tr, patrickvonplaten/common_voice_processed_turkish, patrickvonplaten/helena_coworking, patrickvonplaten/librispeech_asr_dummy, patrickvonplaten/librispeech_local, patrickvonplaten/librispeech_local_dummy, patrickvonplaten/scientific_papers_dummy, pdesoyres/test, peixian/equity_evaluation_corpus, peixian/rtGender, pelican/test_100, pere/norwegian_colossal_corpus_v2_short100k, persiannlp/parsinlu_entailment, persiannlp/parsinlu_query_paraphrasing, persiannlp/parsinlu_reading_comprehension, persiannlp/parsinlu_sentiment, persiannlp/parsinlu_translation_en_fa, persiannlp/parsinlu_translation_fa_en, peterbonnesoeur/autonlp-data-test_text_summarization, peterhsu/github-issues, philschmid/prompted-germanquad, philschmid/test_german_squad, phoelti/squad_dev, phonlab-tcd/cngv1, phonlab-tcd/corpuscrawler-ga, piEsposito/br-quad-2.0, piEsposito/br_quad_20, piEsposito/squad_20_ptbr, pierreant-p/jcvd-or-linkedin, pierreguillou/lener_br_finetuning_language_model, pierreguillou/test_datasetdict, pierresi/cord, pietrolesci/ag_news, poperson1205/mrtydi-v1.1-korean-fixed, princeton-nlp/datasets-for-simcse, priya3301/Graduation_admission, priya3301/tes, priya3301/test, proffttega/ILLUMINATI, proffttega/doc, proffttega/join_illuminati_to_become_rich, proffttega/persian_daily_news, project2you/asr, projecte-aina/ancora-ca-ner, projecte-aina/catalan_general_crawling, projecte-aina/catalan_government_crawling, projecte-aina/catalan_textual_corpus, projecte-aina/parlament_parla, projecte-aina/sts-ca, projecte-aina/teca, projecte-aina/tecla, projecte-aina/vilaquad, projecte-aina/viquiquad, projecte-aina/xquad-ca, psrpsj/stop_words, pstroe/cc100-latin, pulmo/chest_xray, qa4pc/QA4PC, qfortier/instagram_ny, qr/cefr_book_sentences, quarter100/boolq_log, quis/vnexpress-train, qwant/squad_fr, ragarwal/args-me-pairs, rahular/itihasa, rajeshradhakrishnan/malayalam_2020_wiki, rajeshradhakrishnan/malayalam_news, rajeshradhakrishnan/malayalam_wiki, ramitsurana/sanskrit, ramybaly/conll2012, ramybaly/nerd, ranim/Algerian-Arabic, ranpox/xfund, rays2pix/example, rays2pix/example_dataset, readerbench/ChatLinks, rewardsignal/reddit_writing_prompts, rocca/sims4-faces, ronaldvanos/testdata, rony/soccer-dialogues, rookieguy12/dataset, rosettarandd/rosetta_balcanica, roskoN/dailydialog, roskoN/dstc8-reddit-corpus, rubenwol/multi_news_qasrl, rwebe/rwebe, s-myk/test, s3h/arabic-gec, s3h/arabic-grammar-corrections, s3h/custom-qalb-classification, s3h/customized-qalb-v2, s3h/customized-qalb, s3h/gec-arabic, s3h/gec-cleaned, s3h/poc-gec, sagnikrayc/mctest, sagnikrayc/quasar, sagteam/author_profiling, salesken/Paraphrase_category_detection, samarlune/Holy_Coran, samgin/FooReview, samgin/star_tagging, sanyu/aw, sanyu/er, sanyu/hh, sanyu/vb, sc2qa/sc2q_commoncrawl, sc2qa/sc2qa_commoncrawl, sdfufygvjh/fgghuviugviu, seamew/ChnSentiCorp, seamew/Hotel, seamew/THUCNews, seamew/THUCNewsText, seamew/THUCNewsTitle, seamew/Weibo, seanbethard/autonlp-data-summarization_model, sebastiaan/test-cefr, sentence-transformers/embedding-training-data, sentence-transformers/msmarco-hard-negatives, sentence-transformers/parallel-sentences, sentence-transformers/reddit-title-body, seregadgl/test_set, sevbqewre/vebdesbdty, severo/autonlp-data-sentiment_detection-3c8bcd36, severo/wit, seyia92coding/steam_games_2019.csv, shahp7575/test, shahrukhx01/questions-vs-statements, shanya/website_metadata_c4_toy, sharejing/BiPaR, shivkumarganesh/CoLA, shivmoha/squad-unanswerable, shivmoha/squad_adversarial_manual, shpotes/ms_coco, shpotes/tfcol, sijpapi/batch13, sijpapi/funsd, sijpapi/funsds, simplabs/lyrics, sine/zzz, sismetanin/rureviews, smallv0221/my-test, softcatala/Tilde-MODEL-Catalan, softcatala/ca_text_corpus, somaimanguyat/Genjer, somaimanguyat/Koboy, somaimanguyat/Movieonline2021, somaimanguyat/Salome, somaimanguyat/movie21, somaimanguyat/xiomay, spacemanidol/ms_marco_doc2query, spacemanidol/msmarco_passage_ranking, ssasaa/gghghgh, sshleifer/pseudo_bart_xsum, stas/c4-en-10k, stas/openwebtext-10k, stas/oscar-en-10k, stas/wmt14-en-de-pre-processed, stas/wmt16-en-ro-pre-processed, stevhliu/demo, stiel/skjdhjkasdhasjkd, subiksha/OwnDataset, superb/superb-data, susumu2357/squad_v2_sv, svakulenk0/qrecc, svakulenk0/spoken_kgqa, svalabs/all-nli-german-translation-wmt19, svalabs/ms-marco-german-translation-wmt19, svanhvit/iceErrorCorpus, svanhvit/icelandic-ner-MIM-GOLD-NER, tals/test, tanfiona/causenet_wiki, tarudesu/UIT-ViCTSD, tasosk/airlines, tau/scrolls, testOrganization01/test05, teven/c4_15M, teven/matched_passages_wikidata, teven/prompted_examples, teven/stackexchange, tharindu/MOLD, tharindu/SOLID, thiemowa/argumentationreviewcorpus, thiemowa/empathyreviewcorpus, thomwolf/codeparrot-train, thomwolf/codeparrot-valid, thomwolf/codeparrot, thomwolf/github-dataset, thomwolf/github-python, thomwolf/very-good-dataset, thomwolf/very-test-dataset-2, thomwolf/very-test-dataset, tianxing1994/temp, toddmorrill/github-issues, toloka/CrowdSpeech, toloka/VoxDIY-RusNews, tommy19970714/common_voice, toriving/kosimcse, toriving/talktalk-sentiment-210713-multi-singleturn-custom-multiturn, tranduyquang2205/vietnamese_dataset, transformersbook/codeparrot-train, transformersbook/codeparrot-valid, transformersbook/codeparrot, trnt/github-issues, ttj/metadata_arxiv, turingbench/TuringBench, uasoyasser/rgfes, ujjawal1612/quora, unicamp-dl/mmarco, usc-isi/WikiConvert, uva-irlab/canard_quretec, uva-irlab/trec-cast-2019-multi-turn, uyeongjae/load_klue_re_agmented, vanadhi/finlitqa, vannacute/AmazonReviewHelpfulness, vannora/pdata, vasudevgupta/amazon-ml-hack, vasudevgupta/bigbird-tokenized-natural-questions, vasudevgupta/data, vasudevgupta/gsoc-librispeech, vasudevgupta/natural-questions-validation, vasudevgupta/prml_data_contest, vasudevgupta/temperature-distribution-2d-plate, vasudevgupta/temperature-distribution-3d-cylinder, vblagoje/lfqa, vblagoje/lfqa_support_docs, vblagoje/wikipedia_snippets_streamed, vctc92/sdsd, vctc92/test, vera-pro/ShadowLink, versae/bibles, versae/modernisa, versae/norwegian-t5-dataset-debug, versae/norwegian-t5-dataset-debug2, versae/norwegian-t5-dataset-debug3, vershasaxena91/datasets, vershasaxena91/squad_multitask, vesteinn/IC3, vesteinn/icelandic-ner-MIM-GOLD-NER, vidhur2k/multilingual-hate-speech, vishnun/huggingpics-data, vivekverma239/question-generation, vs4vijay/VizDS, w-nicole/childes_data, w-nicole/childes_data_no_tags, w-nicole/childes_data_no_tags_, w-nicole/childes_data_with_tags, w-nicole/childes_data_with_tags_, w11wo/imdb-javanese, wanagenst/maslow-six-choices, wanagenst/maslow-stories, wanagenst/plutchik-nine-choices, wanagenst/plutchik-stories, wanagenst/processed-maslow-stories, wanagenst/processed-swag, wanagenst/reiss-stories, wanagenst/reiss-twenty-choices, wardenga/lsoie, webek18735/ddvoacantonesed, webek18735/dhikhscook, webimmunization/COVID-19-vaccine-attitude-tweets, webis/args_me, webis/conclugen, weijieliu/senteval_cn, wifis/ouivirtual, wikilee/ADFA_Mapping, wikimedia/wikipedia, wikimedia/wikisource, winvoker/turkish-sentiment-analysis-dataset, wisdomify/story, wmt/europarl, wmt/news-commentary, wmt/uncorpus, wmt/wikititles, wmt/wmt10, wmt/wmt13, wmt/wmt14, wmt/wmt15, wmt/wmt16, wmt/wmt17, wmt/wmt18, wmt/wmt19, wzkariampuzha/EpiClassifySet, wzkariampuzha/EpiExtract4GARD, wzywzy/telegram_summary, x-tech/cantonese-mandarin-translations, xiaj/ds_test, xiaj/test0919, xiaobendanyn/demo, xiaobendanyn/nyt10, xiaobendanyn/tacred, xkang/github-issues, xuyeliu/notebookCDG, yannobla/Sunshine, yazdipour/text-to-sparql-kdwd, ydshieh/dummy_coco_dataset, yhavinga/mc4_nl_cleaned, yluisfern/PBU, yo/devparty, ysharma/rickandmorty, ytsaig/news-12factor, yuanchuan/annotated_reference_strings, yuchenlin/OntoRock, yuvalkirstain/asset, yuvalkirstain/quality, yuvalkirstain/quality_squad, yuvalkirstain/quality_squad_debug, yuvalkirstain/squad_full_doc, yxchar/ag-tlm, yxchar/amazon-tlm, yxchar/chemprot-tlm, yxchar/citation_intent-tlm, yxchar/hyp-tlm, yxchar/imdb-tlm, yxchar/rct-20k-tlm, yxchar/sciie-tlm, z-uo/squad-it, zapsdcn/ag, zapsdcn/amazon, zapsdcn/chemprot, zapsdcn/citation_intent, zapsdcn/hyperpartisan_news, zapsdcn/imdb, zapsdcn/rct-20k, zapsdcn/sciie, zf-org/org_dataset, zfaB4Hmm/test, zhangruihan1/face-recognition-validation, zhangruihan1/face-recognition, zhangruihan1/fr-cfp_fp, zj88zj/PubMed_200k_RCT, zj88zj/SCIERC, zloelias/kinopoisk-reviews-short, zloelias/kinopoisk-reviews, zloelias/lenta-ru-short, zloelias/lenta-ru, zlucia/casehold, acronym_identification, ade_corpus_v2, adversarial_qa, aeslc, afrikaans_ner_corpus, ag_news, ai2_arc, air_dialogue, ajgt_twitter_ar, allegro_reviews, allocine, alt, amazon_polarity, amazon_reviews_multi, amazon_us_reviews, ambig_qa, americas_nli, ami, amttl, anli, app_reviews, aqua_rat, aquamuse, ar_cov19, ar_res_reviews, ar_sarcasm, arabic_billion_words, arabic_pos_dialect, arabic_speech_corpus, arcd, arsentd_lev, art, arxiv_dataset, ascent_kb, aslg_pc12, asnq, asset, assin, assin2, atomic, autshumato, babi_qa, banking77, bbaw_egyptian, bbc_hindi_nli, bc2gm_corpus, beans, best2009, bianet, bible_para, big_patent, billsum, bing_coronavirus_query_set, biomrc, biosses, blbooksgenre, blended_skill_talk, blimp, blog_authorship_corpus, bn_hate_speech, bookcorpus, bookcorpusopen, boolq, bprec, break_data, brwac, bsd_ja_en, bswac, c3, c4, cail2018, caner, capes, casino, catalonia_independence, cats_vs_dogs, cawac, cbt, cc100, cc_news, ccaligned_multilingual, cdsc, cdt, cedr, cfq, chr_en, cifar10, cifar100, circa, civil_comments, clickbait_news_bg, climate_fever, clinc_oos, clue, cmrc2018, cmu_hinglish_dog, cnn_dailymail, coached_conv_pref, coarse_discourse, codah, code_search_net, code_x_glue_cc_clone_detection_big_clone_bench, code_x_glue_cc_clone_detection_poj104, code_x_glue_cc_cloze_testing_all, code_x_glue_cc_cloze_testing_maxmin, code_x_glue_cc_code_completion_line, code_x_glue_cc_code_completion_token, code_x_glue_cc_code_refinement, code_x_glue_cc_code_to_code_trans, code_x_glue_cc_defect_detection, code_x_glue_ct_code_to_text, code_x_glue_tc_nl_code_search_adv, code_x_glue_tc_text_to_code, code_x_glue_tt_text_to_text, com_qa, common_gen, common_language, common_voice, commonsense_qa, competition_math, compguesswhat, conceptnet5, conll2000, conll2002, conll2003, conllpp, conv_ai, conv_ai_2, conv_ai_3, conv_questions, coqa, cord19, cornell_movie_dialog, cos_e, cosmos_qa, counter, covid_qa_castorini, covid_qa_deepset, covid_qa_ucsd, covid_tweets_japanese, covost2, craigslist_bargains, crawl_domain, crd3, crime_and_punish, crows_pairs, cryptonite, cs_restaurants, cuad, curiosity_dialogs, daily_dialog, dane, danish_political_comments, dart, datacommons_factcheck, dbpedia_14, dbrd, deal_or_no_dialog, definite_pronoun_resolution, dengue_filipino, dialog_re, diplomacy_detection, disaster_response_messages, discofuse, discovery, disfl_qa, doc2dial, docred, doqa, dream, drop, duorc, dutch_social, dyk, e2e_nlg, e2e_nlg_cleaned, ecb, ecthr_cases, eduge, ehealth_kd, eitb_parcc, eli5, eli5_category, emea, emo, emotion, emotone_ar, empathetic_dialogues, enriched_web_nlg, eraser_multi_rc, esnli, eth_py150_open, ethos, eu_regulatory_ir, eurlex, euronews, europa_eac_tm, europa_ecdc_tm, europarl_bilingual, event2Mind, evidence_infer_treatment, exams, factckbr, fake_news_english, fake_news_filipino, farsi_news, fashion_mnist, fever, few_rel, financial_phrasebank, finer, flores, flue, food101, fquad, freebase_qa, gap, gem, generated_reviews_enth, generics_kb, german_legal_entity_recognition, germaner, germeval_14, giga_fren, gigaword, glucose, glue, gnad10, go_emotions, gooaq, google_wellformed_query, grail_qa, great_code, greek_legal_code, guardian_authorship, gutenberg_time, hans, hansards, hard, harem, has_part, hate_offensive, hate_speech18, hate_speech_filipino, hate_speech_offensive, hate_speech_pl, hate_speech_portuguese, hatexplain, hausa_voa_ner, hausa_voa_topics, hda_nli_hindi, head_qa, health_fact, hebrew_projectbenyehuda, hebrew_sentiment, hebrew_this_world, hellaswag, hendrycks_test, hind_encorp, hindi_discourse, hippocorpus, hkcancor, hlgd, hope_edi, hotpot_qa, hover, hrenwac_para, hrwac, humicroedit, hybrid_qa, hyperpartisan_news_detection, iapp_wiki_qa_squad, id_clickbait, id_liputan6, id_nergrit_corpus, id_newspapers_2018, id_panl_bppt, id_puisi, igbo_english_machine_translation, igbo_monolingual, igbo_ner, ilist, imdb, imdb_urdu_reviews, imppres, indic_glue, indonli, indonlu, inquisitive_qg, interpress_news_category_tr, interpress_news_category_tr_lite, irc_disentangle, isixhosa_ner_corpus, isizulu_ner_corpus, iwslt2017, jeopardy, jfleg, jigsaw_toxicity_pred, jigsaw_unintended_bias, jnlpba, journalists_questions, kan_hope, kannada_news, kd_conv, kde4, kelm, kilt_tasks, kilt_wikipedia, kinnews_kirnews, klue, kor_3i4k, kor_hate, kor_ner, kor_nli, kor_nlu, kor_qpair, kor_sae, kor_sarcasm, labr, lama, lambada, large_spanish_corpus, laroseda, lc_quad, lener_br, lex_glue, liar, librispeech_asr, librispeech_lm, limit, lince, linnaeus, liveqa, lj_speech, lm1b, lst20, m_lama, mac_morpho, makhzan, masakhaner, math_dataset, math_qa, matinf, mbpp, mc4, mc_taco, md_gender_bias, mdd, med_hop, medal, medical_dialog, medical_questions_pairs, menyo20k_mt, meta_woz, metooma, metrec, miam, mkb, mkqa, mlqa, mlsum, mnist, mocha, moroco, movie_rationales, mrqa, ms_marco, ms_terms, msr_genomics_kbcomp, msr_sqa, msr_text_compression, msr_zhen_translation_parity, msra_ner, mt_eng_vietnamese, muchocine, multi_booked, multi_eurlex, multi_news, multi_nli, multi_nli_mismatch, multi_para_crawl, multi_re_qa, multi_woz_v22, multi_x_science_sum, multidoc2dial, multilingual_librispeech, mutual_friends, mwsc, myanmar_news, narrativeqa, narrativeqa_manual, natural_questions, ncbi_disease, nchlt, ncslgr, nell, neural_code_search, news_commentary, newsgroup, newsph, newsph_nli, newspop, newsqa, newsroom, nkjp-ner, nli_tr, nlu_evaluation_data, norec, norne, norwegian_ner, nq_open, nsmc, numer_sense, numeric_fused_head, oclar, offcombr, offenseval2020_tr, offenseval_dravidian, ofis_publik, ohsumed, ollie, omp, onestop_english, onestop_qa, open_subtitles, openai_humaneval, openbookqa, openslr, openwebtext, opinosis, opus100, opus_books, opus_dgt, opus_dogc, opus_elhuyar, opus_euconst, opus_finlex, opus_fiskmo, opus_gnome, opus_infopankki, opus_memat, opus_montenegrinsubs, opus_openoffice, opus_paracrawl, opus_rf, opus_tedtalks, opus_ubuntu, opus_wikipedia, opus_xhosanavy, orange_sum, oscar, para_crawl, para_pat, parsinlu_reading_comprehension, paws, paws-x, pec, peer_read, peoples_daily_ner, per_sent, persian_ner, pg19, php, piaf, pib, piqa, pn_summary, poem_sentiment, polemo2, poleval2019_cyberbullying, poleval2019_mt, polsum, polyglot_ner, prachathai67k, pragmeval, proto_qa, psc, ptb_text_only, pubmed, pubmed_qa, py_ast, qa4mre, qa_srl, qa_zre, qangaroo, qanta, qasc, qasper, qed, qed_amara, quac, quail, quarel, quartz, quora, quoref, race, re_dial, reasoning_bg, recipe_nlg, reclor, reddit, reddit_tifu, refresd, reuters21578, riddle_sense, ro_sent, ro_sts, ro_sts_parallel, roman_urdu, ronec, ropes, rotten_tomatoes, russian_super_glue, s2orc, samsum, sanskrit_classic, saudinewsnet, sberquad, scan, scb_mt_enth_2020, schema_guided_dstc8, scicite, scielo, scientific_papers, scifact, sciq, scitail, scitldr, search_qa, sede, selqa, sem_eval_2010_task_8, sem_eval_2014_task_1, sem_eval_2018_task_1, sem_eval_2020_task_11, sent_comp, senti_lex, senti_ws, sentiment140, sepedi_ner, sesotho_ner_corpus, setimes, setswana_ner_corpus, sharc, sharc_modified, sick, silicone, simple_questions_v2, siswati_ner_corpus, smartdata, sms_spam, snips_built_in_intents, snli, snow_simplified_japanese_corpus, so_stacksample, social_bias_frames, social_i_qa, sofc_materials_articles, sogou_news, spanish_billion_words, spc, species_800, speech_commands, spider, squad, squad_adversarial, squad_es, squad_it, squad_kor_v1, squad_kor_v2, squad_v1_pt, squad_v2, squadshifts, srwac, sst, stereoset, story_cloze, stsb_mt_sv, stsb_multi_mt, style_change_detection, subjqa, super_glue, superb, swag, swahili, swahili_news, swda, swedish_medical_ner, swedish_ner_corpus, swedish_reviews, swiss_judgment_prediction, tab_fact, tamilmixsentiment, tanzil, tapaco, tashkeela, taskmaster1, taskmaster2, taskmaster3, tatoeba, ted_hrlr, ted_iwlst2013, ted_multi, ted_talks_iwslt, telugu_books, telugu_news, tep_en_fa_para, thai_toxicity_tweet, thainer, thaiqa_squad, thaisum, the_pile, the_pile_books3, the_pile_openwebtext2, the_pile_stack_exchange, tilde_model, time_dial, times_of_india_news_headlines, timit_asr, tiny_shakespeare, tlc, tmu_gfm_dataset, totto, trec, trivia_qa, tsac, ttc4900, tunizi, tuple_ie, turk, turkish_movie_sentiment, turkish_ner, turkish_product_reviews, turkish_shrinked_ner, turku_ner_corpus, tweet_eval, tweet_qa, tweets_ar_en_parallel, tweets_hate_speech_detection, twi_text_c3, twi_wordsim353, tydiqa, ubuntu_dialogs_corpus, udhr, um005, un_ga, un_multi, un_pc, universal_dependencies, universal_morphologies, urdu_fake_news, urdu_sentiment_corpus, vctk, vivos, web_nlg, web_of_science, web_questions, weibo_ner, wi_locness, wiki40b, wiki_asp, wiki_atomic_edits, wiki_auto, wiki_bio, wiki_dpr, wiki_hop, wiki_lingua, wiki_movies, wiki_qa, wiki_qa_ar, wiki_snippets, wiki_source, wiki_split, wiki_summary, wikiann, wikicorpus, wikihow, wikipedia, wikisql, wikitext, wikitext_tl39, wili_2018, wino_bias, winograd_wsc, winogrande, wiqa, wisesight1000, wisesight_sentiment, wmt14, wmt15, wmt16, wmt17, wmt18, wmt19, wmt20_mlqe_task1, wmt20_mlqe_task2, wmt20_mlqe_task3, wmt_t2t, wnut_17, wongnai_reviews, woz_dialogue, wrbsc, x_stance, xcopa, xcsr, xed_en_fi, xglue, xnli, xor_tydi_qa, xquad, xquad_r, xsum, xsum_factuality, xtreme, yahoo_answers_qa, yahoo_answers_topics, yelp_polarity, yelp_review_full, yoruba_bbc_topics, yoruba_gv_ner, yoruba_text_c3, yoruba_wordsim353, youtube_caption_corrections, zest, Hamhams/test\n"
     ]
    }
   ],
   "source": [
    "from nlp import list_datasets\n",
    "datasets_list = list_datasets()\n",
    "print(', '.join(dataset.id for dataset in datasets_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select WikiHow data set\n",
    "See more about it at - https://www.tensorflow.org/datasets/catalog/wikihow\n",
    "\n",
    "Manual Download required - Download wikihowAll.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T18:48:48.253885Z",
     "start_time": "2020-09-02T18:48:47.868015Z"
    }
   },
   "outputs": [],
   "source": [
    "from nlp import load_dataset\n",
    "dataset = load_dataset('wikihow', 'all', data_dir='data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T18:48:48.257189Z",
     "start_time": "2020-09-02T18:48:48.255049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['train', 'validation', 'test'])\n"
     ]
    }
   ],
   "source": [
    "print(dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T18:48:48.263225Z",
     "start_time": "2020-09-02T18:48:48.258232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train dataset:  (157252, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of train dataset: \", dataset['train'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T18:48:48.269900Z",
     "start_time": "2020-09-02T18:48:48.264319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Validation dataset:  (5599, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of Validation dataset: \", dataset['validation'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the test data set for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T18:48:48.274748Z",
     "start_time": "2020-09-02T18:48:48.271169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of ca test dataset:  (5577, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of ca test dataset: \", dataset['test'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at Examples in this data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T18:48:48.279408Z",
     "start_time": "2020-09-02T18:48:48.275717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['headline', 'text', 'title'])\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T18:48:48.284043Z",
     "start_time": "2020-09-02T18:48:48.280221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Example of text:  It is possible to become a VFX artist without a college degree, but the path is often easier with one. VFX artists usually major in fine arts, computer graphics, or animation. Choose a college with a reputation for strength in these areas and a reputation for good job placement for graduates. The availability of internships is another factor to consider.Out of the jobs advertised for VFX artists, a majority at any given time specify a bachelor’s degree as a minimum requirement for applicants.;\n",
      ", Some studios offer short-term programs for people who want to learn more about VFX artistry without pursuing a college degree. Enrolling in these programs can be expensive as financial aid isn’t always offered, but they usually have the most cutting edge technology for you to learn from., Although you may create some hand sketches, the majority of your work will be completed on the computer using the most up-to-date programs. Stay informed about the newest software advances by following VFX blogs and taking online computer tutorials.For example, VFX artists are expected to be well-versed in graphics and animation programs, such as Adobe Creative Suite and JavaScript.Clearly list every program that you can work with on your resume.\n",
      " Hop onto YouTube or another video service and search for VFX clip reels or demonstrations. Some of these videos will focus on a particular skill set, such as shading, which you then can practice on your own. Challenge yourself to mimic some of the more difficult tasks, or even try to improve upon the models used., Take as many art and design classes as you can. Or, simply carry a sketch pad around with you to work on your basic animation skills. As you draw, consider factors such as lighting and framing. Even geometry skills can come in handy when creating a particular type of background or even a person’s face.Make a choice to become an observer of the world around you. Ask yourself: how could I capture the movement of the leaves? Or, in what situations do shadows appear?\n",
      "\n",
      ", Watch all of these creations with an eye for detail. Look for the techniques used and any original approaches that you see. Try to recreate any scenes that you find particularly interesting. Research the artists and see what their backgrounds are and contact them if you like., As you gain more experience, you’ll likely find yourself gravitating toward a certain aspect of design. This will become your “calling card” and directors and other professionals will seek you out for this type of work. To build your specialization, start choosing jobs with that emphasis and attend additional training seminars.For example, some VFX specialists focus on human character’s faces, animal figures, or city backgrounds.\n"
     ]
    }
   ],
   "source": [
    "print(\" Example of text: \", dataset['train'][2]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T13:44:38.775524Z",
     "start_time": "2020-09-01T13:44:38.771923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Example of Summary:  Keep related supplies in the same area.\n",
      "Make an effort to clean a dedicated workspace after every session.\n",
      "Place loose supplies in large, clearly visible containers.\n",
      "Use clotheslines and clips to hang sketches, photos, and reference material.\n",
      "Use every inch of the room for storage, especially vertical space.\n",
      "Use chalkboard paint to make space for drafting ideas right on the walls.\n",
      "Purchase a label maker to make your organization strategy semi-permanent.\n",
      "Make a habit of throwing out old, excess, or useless stuff each month.\n"
     ]
    }
   ],
   "source": [
    "print(\" Example of Summary: \", dataset['train'][0]['headline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T13:44:38.780418Z",
     "start_time": "2020-09-01T13:44:38.776344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Example of Title:  How to Be an Organized Artist1\n"
     ]
    }
   ],
   "source": [
    "print(\" Example of Title: \", dataset['train'][0]['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate average length of Text and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T13:44:38.785557Z",
     "start_time": "2020-09-01T13:44:38.781468Z"
    }
   },
   "outputs": [],
   "source": [
    "tiny_dataset = dataset['train'].select(list(range(0, 100)))\n",
    "text_len = []\n",
    "summary_len=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T13:44:38.801235Z",
     "start_time": "2020-09-01T13:44:38.786503Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(tiny_dataset)):\n",
    "    example = tiny_dataset[i]\n",
    "    text_example = example['text']\n",
    "    text_example = text_example.replace('\\n','')\n",
    "    text_words = text_example.split()\n",
    "    text_len.append(len(text_words))\n",
    "    summary_example = example['headline']\n",
    "    summary_example = summary_example.replace('\\n','')\n",
    "    summary_words = summary_example.split()\n",
    "    summary_len.append(len(summary_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T18:46:50.185114Z",
     "start_time": "2020-09-02T18:46:50.047191Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(text_len)\n",
    "plt.title('Text Length Distribution - First 100 examples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T18:47:08.641831Z",
     "start_time": "2020-09-02T18:47:08.524395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(summary_len)\n",
    "plt.title('Summary Length Distribution - First 100 examples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T13:44:39.138817Z",
     "start_time": "2020-09-01T13:44:39.136486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Length of text:  662.69\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Length of text: \", sum(text_len)/len(text_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T13:44:39.143573Z",
     "start_time": "2020-09-01T13:44:39.139797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Length of Summary:  48.8\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Length of Summary: \", sum(summary_len)/len(summary_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T13:44:39.162456Z",
     "start_time": "2020-09-01T13:44:39.144570Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T13:44:39.185299Z",
     "start_time": "2020-09-01T13:44:39.163413Z"
    }
   },
   "outputs": [],
   "source": [
    "class T5FineTuner(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super(T5FineTuner, self).__init__()\n",
    "        self.hparams = hparams        \n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(hparams.model_name_or_path)\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(hparams.tokenizer_name_or_path)\n",
    "        self.rouge_metric = load_metric('rouge') \n",
    "        \n",
    "        if self.hparams.freeze_embeds:\n",
    "            self.freeze_embeds()\n",
    "        if self.hparams.freeze_encoder:\n",
    "            self.freeze_params(self.model.get_encoder())\n",
    "            assert_all_frozen(self.model.get_encoder())\n",
    "            \n",
    "            \n",
    "        n_observations_per_split = {\n",
    "            \"train\": self.hparams.n_train,\n",
    "            \"validation\": self.hparams.n_val,\n",
    "            \"test\": self.hparams.n_test,\n",
    "        }\n",
    "        self.n_obs = {k: v if v >= 0 else None for k, v in n_observations_per_split.items()}\n",
    "        \n",
    "    \n",
    "    def freeze_params(self, model):\n",
    "        for par in model.parameters():\n",
    "            par.requires_grad = False\n",
    "            \n",
    "            \n",
    "    def freeze_embeds(self):\n",
    "        \"\"\"Freeze token embeddings and positional embeddings for bart, just token embeddings for t5.\"\"\"\n",
    "        try:\n",
    "            self.freeze_params(self.model.model.shared)\n",
    "            for d in [self.model.model.encoder, self.model.model.decoder]:\n",
    "                freeze_params(d.embed_positions)\n",
    "                freeze_params(d.embed_tokens)\n",
    "        except AttributeError:\n",
    "            self.freeze_params(self.model.shared)\n",
    "            for d in [self.model.encoder, self.model.decoder]:\n",
    "                self.freeze_params(d.embed_tokens)\n",
    "    \n",
    "    def lmap(self, f, x):\n",
    "        \"\"\"list(map(f, x))\"\"\"\n",
    "        return list(map(f, x))\n",
    "    \n",
    "\n",
    "    def is_logger(self):\n",
    "        return self.trainer.proc_rank <= 0\n",
    "    \n",
    "    \n",
    "    def parse_score(self, result):\n",
    "        return {k: round(v.mid.fmeasure * 100, 4) for k, v in result.items()}\n",
    "        \n",
    "    def forward(\n",
    "      self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, lm_labels=None\n",
    "  ):\n",
    "        return self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            lm_labels=lm_labels,\n",
    "    )\n",
    "\n",
    "    def _step(self, batch):\n",
    "        lm_labels = batch[\"target_ids\"]\n",
    "        lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        outputs = self(\n",
    "            input_ids=batch[\"source_ids\"],\n",
    "            attention_mask=batch[\"source_mask\"],\n",
    "            lm_labels=lm_labels,\n",
    "            decoder_attention_mask=batch['target_mask']\n",
    "        )\n",
    "\n",
    "        loss = outputs[0]\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def ids_to_clean_text(self, generated_ids):\n",
    "        gen_text = self.tokenizer.batch_decode(\n",
    "            generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "        )\n",
    "        return self.lmap(str.strip, gen_text)\n",
    "    \n",
    "    \n",
    "    def _generative_step(self, batch) :\n",
    "        \n",
    "        t0 = time.time()\n",
    "        \n",
    "        generated_ids = self.model.generate(\n",
    "            batch[\"source_ids\"],\n",
    "            attention_mask=batch[\"source_mask\"],\n",
    "            use_cache=True,\n",
    "            decoder_attention_mask=batch['target_mask'],\n",
    "            max_length=150, \n",
    "            num_beams=2,\n",
    "            repetition_penalty=2.5, \n",
    "            length_penalty=1.0, \n",
    "            early_stopping=True\n",
    "        )\n",
    "        preds = self.ids_to_clean_text(generated_ids)\n",
    "        target = self.ids_to_clean_text(batch[\"target_ids\"])\n",
    "            \n",
    "        gen_time = (time.time() - t0) / batch[\"source_ids\"].shape[0]  \n",
    "    \n",
    "        loss = self._step(batch)\n",
    "        base_metrics = {'val_loss': loss}\n",
    "#         rouge: Dict = self.calc_generative_metrics(preds, target)\n",
    "        summ_len = np.mean(self.lmap(len, generated_ids))\n",
    "        base_metrics.update(gen_time=gen_time, gen_len=summ_len, preds=preds, target=target)\n",
    "        self.rouge_metric.add_batch(preds, target)\n",
    "        \n",
    "#         rouge_results = self.rouge_metric.compute() \n",
    "#         rouge_dict = self.parse_score(rouge_results)\n",
    "#         base_metrics.update(rouge1=rouge_dict['rouge1'], rougeL=rouge_dict['rougeL'])\n",
    "        \n",
    "        return base_metrics\n",
    "    \n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "\n",
    "        tensorboard_logs = {\"train_loss\": loss}\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "  \n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_train_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        tensorboard_logs = {\"avg_train_loss\": avg_train_loss}\n",
    "        return {\"avg_train_loss\": avg_train_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._generative_step(batch)\n",
    "    \n",
    "  \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        \n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        tensorboard_logs = {\"val_loss\": avg_loss}\n",
    "        \n",
    "        rouge_results = self.rouge_metric.compute() \n",
    "        rouge_dict = self.parse_score(rouge_results)\n",
    "    \n",
    "        tensorboard_logs.update(rouge1=rouge_dict['rouge1'], rougeL=rouge_dict['rougeL'])\n",
    "        \n",
    "        ## Clear out the lists for next epoch\n",
    "        self.target_gen= []\n",
    "        self.prediction_gen=[]\n",
    "        return {\"avg_val_loss\": avg_loss, \n",
    "                \"rouge1\" : rouge_results['rouge1'],\n",
    "                \"rougeL\" : rouge_results['rougeL'],\n",
    "                \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
    "\n",
    "        model = self.model\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": self.hparams.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon)\n",
    "        self.opt = optimizer\n",
    "        return [optimizer]\n",
    "  \n",
    "    def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx, second_order_closure=None, using_native_amp=False):\n",
    "        if self.trainer.use_tpu:\n",
    "            xm.optimizer_step(optimizer)\n",
    "        else:\n",
    "            optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        self.lr_scheduler.step()\n",
    "  \n",
    "    def get_tqdm_dict(self):\n",
    "        tqdm_dict = {\"loss\": \"{:.3f}\".format(self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n",
    "\n",
    "        return tqdm_dict\n",
    "    \n",
    "\n",
    "    def train_dataloader(self):   \n",
    "        n_samples = self.n_obs['train']\n",
    "        train_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"train\", num_samples=n_samples, args=self.hparams)\n",
    "        dataloader = DataLoader(train_dataset, batch_size=self.hparams.train_batch_size, drop_last=True, shuffle=True, num_workers=4)\n",
    "        t_total = (\n",
    "            (len(dataloader.dataset) // (self.hparams.train_batch_size * max(1, self.hparams.n_gpu)))\n",
    "            // self.hparams.gradient_accumulation_steps\n",
    "            * float(self.hparams.num_train_epochs)\n",
    "        )\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            self.opt, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=t_total\n",
    "        )\n",
    "        self.lr_scheduler = scheduler\n",
    "        return dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        n_samples = self.n_obs['validation']\n",
    "        validation_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"validation\", num_samples=n_samples, args=self.hparams)\n",
    "        \n",
    "        return DataLoader(validation_dataset, batch_size=self.hparams.eval_batch_size, num_workers=4)\n",
    "    \n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        n_samples = self.n_obs['test']\n",
    "        test_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"test\", num_samples=n_samples, args=self.hparams)\n",
    "        \n",
    "        return DataLoader(test_dataset, batch_size=self.hparams.eval_batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T13:44:39.192404Z",
     "start_time": "2020-09-01T13:44:39.186281Z"
    }
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class LoggingCallback(pl.Callback):\n",
    "    def on_validation_end(self, trainer, pl_module):\n",
    "        logger.info(\"***** Validation results *****\")\n",
    "        if pl_module.is_logger():\n",
    "            metrics = trainer.callback_metrics\n",
    "            # Log results\n",
    "            for key in sorted(metrics):\n",
    "                if key not in [\"log\", \"progress_bar\"]:\n",
    "                    logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "\n",
    "    def on_test_end(self, trainer, pl_module):\n",
    "        logger.info(\"***** Test results *****\")\n",
    "\n",
    "        if pl_module.is_logger():\n",
    "            metrics = trainer.callback_metrics\n",
    "\n",
    "            # Log and save results to file\n",
    "            output_test_results_file = os.path.join(pl_module.hparams.output_dir, \"test_results.txt\")\n",
    "            with open(output_test_results_file, \"w\") as writer:\n",
    "                for key in sorted(metrics):\n",
    "                    if key not in [\"log\", \"progress_bar\"]:\n",
    "                        logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "                        writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a DataSet class for the loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T13:44:39.203467Z",
     "start_time": "2020-09-01T13:44:39.193447Z"
    }
   },
   "outputs": [],
   "source": [
    "class wikihow(Dataset):\n",
    "    def __init__(self, tokenizer, type_path, num_samples, input_length, output_length, print_text=False):         \n",
    "        self.dataset =  load_dataset('wikihow', 'all', data_dir='data/', split=type_path)\n",
    "        if num_samples:\n",
    "            self.dataset = self.dataset.select(list(range(0, num_samples)))\n",
    "        self.input_length = input_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.output_length = output_length\n",
    "        self.print_text = print_text\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        text = text.replace('Example of text:', '')\n",
    "        text = text.replace('Example of Summary:', '')\n",
    "        text = text.replace('\\n','')\n",
    "        text = text.replace('``', '')\n",
    "        text = text.replace('\"', '')\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    \n",
    "    def convert_to_features(self, example_batch):\n",
    "        # Tokenize contexts and questions (as pairs of inputs)\n",
    "        \n",
    "        if self.print_text:\n",
    "            print(\"Input Text: \", self.clean_text(example_batch['text']))\n",
    "#         input_ = self.clean_text(example_batch['text']) + \" </s>\"\n",
    "#         target_ = self.clean_text(example_batch['headline']) + \" </s>\"\n",
    "        \n",
    "        input_ = self.clean_text(example_batch['text'])\n",
    "        target_ = self.clean_text(example_batch['headline'])\n",
    "        \n",
    "        source = self.tokenizer.batch_encode_plus([input_], max_length=self.input_length, \n",
    "                                                     padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "        \n",
    "        targets = self.tokenizer.batch_encode_plus([target_], max_length=self.output_length, \n",
    "                                                     padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "    \n",
    "       \n",
    "        return source, targets\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        source, targets = self.convert_to_features(self.dataset[index])\n",
    "        \n",
    "        source_ids = source[\"input_ids\"].squeeze()\n",
    "        target_ids = targets[\"input_ids\"].squeeze()\n",
    "\n",
    "        src_mask    = source[\"attention_mask\"].squeeze()\n",
    "        target_mask = targets[\"attention_mask\"].squeeze()\n",
    "\n",
    "        return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the dataset function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T18:55:41.647100Z",
     "start_time": "2020-09-02T18:55:41.023703Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5599"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "dataset = wikihow(tokenizer, 'validation', None, 512, 150, True)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T18:55:43.381341Z",
     "start_time": "2020-09-02T18:55:43.366366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text:  You can use a smaller size (3/4 inch is used here), but it won't be as strong.;, Be sure that the feet are headed in the same direction and the shape is as squared as you can get it. It is very easy to get turned around. You want it to shrink somewhat (like it would naturally) before you affix it to the frame.If you are going to be making a quilted bed, do what you need to, to get it ready. The soft part of this setup is a small velour blanket folded into quarters., You could use rivets, snaps, hooks, even Velcro. Keep in mind that you are going to have to clean it periodically.A particularly easy method is to sew the material around the sides, but you won't be able to glue the legs to the corner ends, completely.\n",
      "\n",
      "Shape of Tokenized Text:  torch.Size([512])\n",
      "\n",
      "Sanity check - Decode Text:  You can use a smaller size (3/4 inch is used here), but it won't be as strong.;, Be sure that the feet are headed in the same direction and the shape is as squared as you can get it. It is very easy to get turned around. You want it to shrink somewhat (like it would naturally) before you affix it to the frame.If you are going to be making a quilted bed, do what you need to, to get it ready. The soft part of this setup is a small velour blanket folded into quarters., You could use rivets, snaps, hooks, even Velcro. Keep in mind that you are going to have to clean it periodically.A particularly easy method is to sew the material around the sides, but you won't be able to glue the legs to the corner ends, completely.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "====================================\n",
      "Sanity check - Decode Summary:  Get your PVC pieces all together.Start assembling them.If your cloth that you will be using is new, wash it.Take the larger sheet of material and wrap it around the sides of the bed.,Find some way of fastening them.Finished.</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "data = dataset[50]\n",
    "print()\n",
    "print(\"Shape of Tokenized Text: \", data['source_ids'].shape)\n",
    "print()\n",
    "print(\"Sanity check - Decode Text: \", tokenizer.decode(data['source_ids']))\n",
    "print(\"====================================\")\n",
    "print(\"Sanity check - Decode Summary: \", tokenizer.decode(data['target_ids']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T13:44:39.830252Z",
     "start_time": "2020-09-01T13:44:39.824446Z"
    }
   },
   "outputs": [],
   "source": [
    "args_dict = dict(\n",
    "    output_dir=\"\", # path to save the checkpoints\n",
    "    model_name_or_path='t5-small',\n",
    "    tokenizer_name_or_path='t5-small',\n",
    "    max_input_length=512,\n",
    "    max_output_length=150,\n",
    "    freeze_encoder=False,\n",
    "    freeze_embeds=False,\n",
    "    learning_rate=3e-4,\n",
    "    weight_decay=0.0,\n",
    "    adam_epsilon=1e-8,\n",
    "    warmup_steps=0,\n",
    "    train_batch_size=4,\n",
    "    eval_batch_size=4,\n",
    "    num_train_epochs=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    n_gpu=1,\n",
    "    resume_from_checkpoint=None, \n",
    "    val_check_interval = 0.05, \n",
    "    n_val=1000,\n",
    "    n_train=-1,\n",
    "    n_test=-1,\n",
    "    early_stop_callback=False,\n",
    "    fp_16=False, # if you want to enable 16-bit training then install apex and set this to true\n",
    "    opt_level='O1', # you can find out more on optimisation levels here https://nvidia.github.io/apex/amp.html#opt-levels-and-properties\n",
    "    max_grad_norm=1.0, # if you enable 16-bit training then set this to a sensible value, 0.5 is a good default\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T13:28:40.222324Z",
     "start_time": "2020-09-01T13:28:40.103545Z"
    }
   },
   "source": [
    "!mkdir -p t5_wikihow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T13:44:39.836856Z",
     "start_time": "2020-09-01T13:44:39.831154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output_dir': 't5_wikihow', 'model_name_or_path': 't5-small', 'tokenizer_name_or_path': 't5-small', 'max_input_length': 512, 'max_output_length': 150, 'freeze_encoder': False, 'freeze_embeds': False, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'warmup_steps': 0, 'train_batch_size': 4, 'eval_batch_size': 4, 'num_train_epochs': 2, 'gradient_accumulation_steps': 8, 'n_gpu': 1, 'resume_from_checkpoint': None, 'val_check_interval': 0.05, 'n_val': 1000, 'n_train': -1, 'n_test': -1, 'early_stop_callback': False, 'fp_16': False, 'opt_level': 'O1', 'max_grad_norm': 1.0, 'seed': 42}\n"
     ]
    }
   ],
   "source": [
    "args_dict.update({'output_dir': 't5_wikihow', 'num_train_epochs':2,\n",
    "                 'train_batch_size': 4, 'eval_batch_size': 4})\n",
    "args = argparse.Namespace(**args_dict)\n",
    "print(args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T13:44:39.843602Z",
     "start_time": "2020-09-01T13:44:39.837733Z"
    }
   },
   "outputs": [],
   "source": [
    "## Define Checkpoint function\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    filepath=args.output_dir, prefix=\"checkpoint\", monitor=\"val_loss\", mode=\"min\", save_top_k=3\n",
    ")\n",
    "\n",
    "## If resuming from checkpoint, add an arg resume_from_checkpoint\n",
    "train_params = dict(\n",
    "    accumulate_grad_batches=args.gradient_accumulation_steps,\n",
    "    gpus=args.n_gpu,\n",
    "    max_epochs=args.num_train_epochs,\n",
    "    early_stop_callback=False,\n",
    "    precision= 16 if args.fp_16 else 32,\n",
    "    amp_level=args.opt_level,\n",
    "    resume_from_checkpoint=args.resume_from_checkpoint,\n",
    "    gradient_clip_val=args.max_grad_norm,\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "    val_check_interval=args.val_check_interval,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[LoggingCallback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T13:44:39.853037Z",
     "start_time": "2020-09-01T13:44:39.844578Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataset(tokenizer, type_path, num_samples, args):\n",
    "      return wikihow(tokenizer=tokenizer, type_path=type_path, num_samples=num_samples,  input_length=args.max_input_length, \n",
    "                        output_length=args.max_output_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T13:44:42.048444Z",
     "start_time": "2020-09-01T13:44:39.854009Z"
    }
   },
   "outputs": [],
   "source": [
    "model = T5FineTuner(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T13:44:42.072260Z",
     "start_time": "2020-09-01T13:44:42.053193Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T20:25:25.960117Z",
     "start_time": "2020-09-01T13:44:42.076449Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 60 M  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ce34c5a1ec4b568f4ace8657f6a423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T00:59:41.863404Z",
     "start_time": "2020-09-02T00:59:41.859895Z"
    }
   },
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T01:00:09.047610Z",
     "start_time": "2020-09-02T01:00:08.417634Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "dataset = wikihow(tokenizer, 'test', None, 512, 150, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T01:00:29.151446Z",
     "start_time": "2020-09-02T01:00:29.143943Z"
    }
   },
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "it = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T01:00:34.602089Z",
     "start_time": "2020-09-02T01:00:34.443983Z"
    }
   },
   "outputs": [],
   "source": [
    "batch = next(it)\n",
    "batch[\"source_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T01:02:59.809227Z",
     "start_time": "2020-09-02T01:02:51.326688Z"
    }
   },
   "outputs": [],
   "source": [
    "model.to('cuda')\n",
    "outs = model.model.generate(\n",
    "            batch[\"source_ids\"].cuda(),\n",
    "            attention_mask=batch[\"source_mask\"].cuda(),\n",
    "            use_cache=True,\n",
    "            decoder_attention_mask=batch['target_mask'].cuda(),\n",
    "            max_length=150, \n",
    "            num_beams=2,\n",
    "            repetition_penalty=2.5, \n",
    "            length_penalty=1.0, \n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "dec = [tokenizer.decode(ids) for ids in outs]\n",
    "\n",
    "texts = [tokenizer.decode(ids) for ids in batch['source_ids']]\n",
    "targets = [tokenizer.decode(ids) for ids in batch['target_ids']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T01:03:57.193269Z",
     "start_time": "2020-09-02T01:03:57.138546Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(32):\n",
    "    lines = textwrap.wrap(\"WikiHow Text:\\n%s\\n\" % texts[i], width=100)\n",
    "    print(\"\\n\".join(lines))\n",
    "    print(\"\\nActual Summary: %s\" % targets[i])\n",
    "    print(\"\\nPredicted Summary: %s\" % dec[i])\n",
    "    print(\"=====================================================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing using AutoModel loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-06T12:11:08.098275Z",
     "start_time": "2020-09-06T12:11:08.096343Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-06T12:11:12.532641Z",
     "start_time": "2020-09-06T12:11:09.708535Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"deep-learning-analytics/wikihow-t5-small\")\n",
    "\n",
    "model = AutoModelWithLMHead.from_pretrained(\"deep-learning-analytics/wikihow-t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-06T12:11:14.162773Z",
     "start_time": "2020-09-06T12:11:12.533612Z"
    }
   },
   "outputs": [],
   "source": [
    "## Move to CUDA\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-06T12:11:19.675892Z",
     "start_time": "2020-09-06T12:11:19.670482Z"
    }
   },
   "outputs": [],
   "source": [
    "text = \"\"\"\"\n",
    "Lack of fluids can lead to dry mouth, which is a leading cause of bad breath. Water\n",
    "can also dilute any chemicals in your mouth or gut that are causing bad breath., Studies show that\n",
    "eating 6 ounces of yogurt a day reduces the level of odor-causing compounds in the mouth. In\n",
    "particular, look for yogurt containing the active bacteria Streptococcus thermophilus or\n",
    "Lactobacillus bulgaricus., The abrasive nature of fibrous fruits and vegetables helps to clean\n",
    "teeth, while the vitamins, antioxidants, and acids they contain improve dental health.Foods that can\n",
    "be particularly helpful include:Apples — Apples contain vitamin C, which is necessary for health\n",
    "gums, as well as malic acid, which helps to whiten teeth.Carrots — Carrots are rich in vitamin A,\n",
    "which strengthens tooth enamel.Celery — Chewing celery produces a lot of saliva, which helps to\n",
    "neutralize bacteria that cause bad breath.Pineapples — Pineapples contain bromelain, an enzyme that\n",
    "cleans the mouth., These teas have been shown to kill the bacteria that cause bad breath and\n",
    "plaque., An upset stomach can lead to burping, which contributes to bad breath. Don’t eat foods that\n",
    "upset your stomach, or if you do, use antacids. If you are lactose intolerant, try lactase tablets.,\n",
    "They can all cause bad breath. If you do eat them, bring sugar-free gum or a toothbrush and\n",
    "toothpaste to freshen your mouth afterwards., Diets low in carbohydrates lead to ketosis — a state\n",
    "in which the body burns primarily fat instead of carbohydrates for energy. This may be good for your\n",
    "waistline, but it also produces chemicals called ketones, which contribute to bad breath.To stop the\n",
    "problem, you must change your diet. Or, you can combat the smell in one of these ways:Drink lots of\n",
    "water to dilute the ketones.Chew sugarless gum or suck on sugarless mints.Chew mint leaves.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-06T12:11:25.940815Z",
     "start_time": "2020-09-06T12:11:25.937188Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocess_text = text.strip().replace(\"\\n\",\"\")\n",
    "tokenized_text = tokenizer.encode(preprocess_text, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-06T12:11:32.501144Z",
     "start_time": "2020-09-06T12:11:31.917512Z"
    }
   },
   "outputs": [],
   "source": [
    "summary_ids = model.generate(\n",
    "            tokenized_text,\n",
    "            max_length=150, \n",
    "            num_beams=2,\n",
    "            repetition_penalty=2.5, \n",
    "            length_penalty=1.0, \n",
    "            early_stopping=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-06T12:11:38.309701Z",
     "start_time": "2020-09-06T12:11:38.289453Z"
    }
   },
   "outputs": [],
   "source": [
    "output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print (\"\\n\\nSummarized text: \\n\",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
